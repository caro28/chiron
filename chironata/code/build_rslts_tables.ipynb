{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4218d72e-c3c2-495d-92fe-6f68d9f8f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from functions import load_txt_as_lst\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc916d9d-07fd-4a46-8e13-bae64050f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### vecalign function ####\n",
    "def read_alignments(fin):\n",
    "    alignments = []\n",
    "    with open(fin, 'rt', encoding=\"utf-8\") as infile:\n",
    "        for line in infile:\n",
    "            fields = [x.strip() for x in line.split(':') if len(x.strip())]\n",
    "            if len(fields) < 2:\n",
    "                raise Exception('Got line \"%s\", which does not have at least two \":\" separated fields' % line.strip())\n",
    "            try:\n",
    "                src = literal_eval(fields[0])\n",
    "                tgt = literal_eval(fields[1])\n",
    "            except:\n",
    "                raise Exception('Failed to parse line \"%s\"' % line.strip())\n",
    "            alignments.append((src, tgt))\n",
    "\n",
    "    # I know bluealign files have a few entries entries missing,\n",
    "    #   but I don't fix them in order to be consistent previous reported scores\n",
    "    return alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15005e3b-b33b-47f2-bbe3-6c850979a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "th1_rslts = read_alignments(\"/home/craig.car/repos/chiron/chironata/data/alignments_rslts/thucydides_1863.rslts\")\n",
    "th2_rslts = read_alignments(\"/home/craig.car/repos/chiron/chironata/data/alignments_rslts/thucydides_1_1852.rslts\")\n",
    "el_sents = load_txt_as_lst(\"/home/craig.car/repos/chiron/chironata/data/src_data/urn:cts:greekLit:tlg0003.tlg001.sents\")\n",
    "th1_sents = load_txt_as_lst(\"/home/craig.car/repos/chiron/chironata/data/french_trans-dev/thucydides_1863.sents\")\n",
    "th2_sents = load_txt_as_lst(\"/home/craig.car/repos/chiron/chironata/data/french_trans-dev/thucydides_1_1852.sents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba28008-e9ef-4337-9821-ed132ea1ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_src_2_tgt_dict(alignments_lst):\n",
    "    '''\n",
    "    If alignment is null on one side, inserts \"null\" \n",
    "    '''\n",
    "    src_id_to_tgt_ids = defaultdict(set)\n",
    "    for src, tgt in alignments_lst:\n",
    "        if src == []:\n",
    "            src = [\"null\"]\n",
    "        if tgt == []:\n",
    "            tgt = [\"null\"]\n",
    "        for src_id in src:\n",
    "            for tgt_id in tgt:\n",
    "                src_id_to_tgt_ids[src_id].add(tgt_id)\n",
    "    return src_id_to_tgt_ids\n",
    "\n",
    "def build_tgt_2_src_dict(alignments_lst):\n",
    "    '''\n",
    "    If alignment is null on one side, inserts \"null\" \n",
    "    '''\n",
    "    # tgt_id_to_src_ids = defaultdict(set)\n",
    "    tgt_id_to_src_ids = {}\n",
    "    for src, tgt in alignments_lst:\n",
    "        if src == []:\n",
    "            src = [\"null\"]\n",
    "        if tgt == []:\n",
    "            tgt = [\"null\"]\n",
    "        for tgt_id in tgt:\n",
    "            for src_id in src:\n",
    "                if tgt_id in tgt_id_to_src_ids.keys():\n",
    "                    tgt_id_to_src_ids[tgt_id].add(src_id)\n",
    "                else:\n",
    "                    tgt_id_to_src_ids[tgt_id] = {src_id}\n",
    "                # tgt_id_to_src_ids[tgt_id].add(src_id)\n",
    "    return tgt_id_to_src_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf40832-91ae-4aa4-a60c-739e059de1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "el2th1 = build_src_2_tgt_dict(th1_rslts)\n",
    "el2th2 = build_src_2_tgt_dict(th2_rslts)\n",
    "\n",
    "th1_2_el = build_tgt_2_src_dict(th1_rslts)\n",
    "th2_2_el = build_tgt_2_src_dict(th2_rslts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00ede46-28da-4cdc-92db-8dace0ca484e",
   "metadata": {},
   "source": [
    "## TODO: problem with iterating through alignments: how to capture []:[tgt] in th2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a43de36-a18b-4005-95f5-6cfc737e7a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{35, 36, 37, 38}\n",
      "{110, 111}\n",
      "{89, 90}\n"
     ]
    }
   ],
   "source": [
    "#### iterate through el indices #### \n",
    "\n",
    "# for sent_idx in range(len(el2th1)):\n",
    "el_series = []\n",
    "th1_series = []\n",
    "th2_series = []\n",
    "\n",
    "building_src = set()\n",
    "building_tgt_th1 = set()\n",
    "building_tgt_th2 = set()\n",
    "\n",
    "for sent_idx in range(35,39):\n",
    "    # get tgt preds for src idx across all translations\n",
    "    el_2_th1_tgt_preds = el2th1[sent_idx]\n",
    "    el_2_th2_tgt_preds = el2th2[sent_idx]\n",
    "    \n",
    "    # get src preds for all tgt preds across all translations\n",
    "    el_2_th1_src_preds = set()\n",
    "    for tgt_pred in el_2_th1_tgt_preds:\n",
    "        src_preds = th1_2_el[tgt_pred]\n",
    "        el_2_th1_src_preds.update(src_preds)\n",
    "    \n",
    "    el_2_th2_src_preds = set()\n",
    "    for tgt_pred in el_2_th2_tgt_preds:\n",
    "        src_preds = th2_2_el[tgt_pred]\n",
    "        el_2_th2_src_preds.update(src_preds)\n",
    "    \n",
    "    # check that no tgt preds are missing\n",
    "    for src_pred in el_2_th1_src_preds:\n",
    "        tgt_preds = el2th1[src_pred]\n",
    "        el_2_th1_tgt_preds.update(tgt_preds)\n",
    "    \n",
    "    for src_pred in el_2_th2_src_preds:\n",
    "        tgt_preds = el2th2[src_pred]\n",
    "        el_2_th2_tgt_preds.update(tgt_preds)\n",
    "    src_max = max(len(el_2_th1_src_preds), len(el_2_th2_src_preds))\n",
    "    tgt_max = max(len(el_2_th1_tgt_preds), len(el_2_th2_tgt_preds))\n",
    "    \n",
    "    building_src.update(el_2_th1_src_preds)\n",
    "    building_src.update(el_2_th2_src_preds)\n",
    "    building_tgt_th1.update(el_2_th1_tgt_preds)\n",
    "    building_tgt_th2.update(el_2_th2_tgt_preds)\n",
    "    \n",
    "\n",
    "print(building_src)\n",
    "print(building_tgt_th1)\n",
    "print(building_tgt_th2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a784c0ce-022d-41d2-b155-86990322647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### iterate through pred alignments of 1st translation ###\n",
    "\n",
    "el_series_idx = []\n",
    "th1_series_idx = []\n",
    "th2_series_idx = []\n",
    "\n",
    "building_src = set()\n",
    "\n",
    "visited_el = set()\n",
    "\n",
    "for alignment in th1_rslts:\n",
    "    src_preds_th1 = set(alignment[0])\n",
    "    tgt_preds_th1 = set(alignment[1])\n",
    "    \n",
    "    if src_preds_th1 == set():\n",
    "        el_series_idx.append(set())\n",
    "        th1_series_idx.append(tgt_preds_th1)\n",
    "    else:\n",
    "    \n",
    "        for idx in src_preds_th1:\n",
    "            if idx in visited_el:\n",
    "                # print(idx)\n",
    "                continue\n",
    "            else:\n",
    "                building_src.update(src_preds_th1)\n",
    "                # get tgt from th2\n",
    "                tgt_preds_th2 = set()\n",
    "                for src_pred in building_src:\n",
    "                    tgt_preds = el2th2[src_pred]\n",
    "                    tgt_preds_th2.update(tgt_preds)\n",
    "                # check for any missing src\n",
    "                for tgt_pred in tgt_preds_th1:\n",
    "                    src_preds = th1_2_el[tgt_pred]\n",
    "                    building_src.update(src_preds)\n",
    "\n",
    "                for tgt_pred in tgt_preds_th2:\n",
    "                    src_preds = th2_2_el[tgt_pred]\n",
    "                    building_src.update(src_preds)\n",
    "\n",
    "                # get tgt for any new src:\n",
    "                for src in building_src:\n",
    "                    tgt_preds_th1.update(el2th1[src])\n",
    "                    tgt_preds_th2.update(el2th2[src])\n",
    "                # print(f\"%%{building_src}, {tgt_preds_th1}, {tgt_preds_th2}\")\n",
    "\n",
    "                # get src for any new tgt:\n",
    "                for tgt in tgt_preds_th1:\n",
    "                    building_src.update(th1_2_el[tgt])\n",
    "                for tgt in tgt_preds_th2:\n",
    "                    building_src.update(th2_2_el[tgt])\n",
    "                # print(f\"%%{building_src}, {tgt_preds_th1}, {tgt_preds_th2}\")\n",
    "\n",
    "                # get tgt for any new src:\n",
    "                for src in building_src:\n",
    "                    tgt_preds_th1.update(el2th1[src])\n",
    "                    tgt_preds_th2.update(el2th2[src])\n",
    "                # print(f\"%%{building_src}, {tgt_preds_th1}, {tgt_preds_th2}\")\n",
    "\n",
    "                # add to visited_el\n",
    "                visited_el.update(building_src)\n",
    "\n",
    "                # add to series\n",
    "                el_series_idx.append(building_src)\n",
    "                th1_series_idx.append(tgt_preds_th1)\n",
    "                th2_series_idx.append(tgt_preds_th2)\n",
    "                building_src = set()\n",
    "    \n",
    "# print(el_series)\n",
    "# print(th1_series)\n",
    "# print(th2_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1a535b9-4e99-4cdd-a832-8c8c5bc14020",
   "metadata": {},
   "outputs": [],
   "source": [
    "el_series = []\n",
    "for idx_set in el_series_idx:\n",
    "    if idx_set == set():\n",
    "        el_series.append(\"\")\n",
    "    else:\n",
    "        row = \"\"\n",
    "        for idx in idx_set:\n",
    "            sent = el_sents[idx]\n",
    "            row += f\"[{idx}] {sent}\\n\"\n",
    "        el_series.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a67bb897-1660-4214-9a79-7487c5124569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4631"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(el_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fa16410-517c-49b0-8b8b-a9331519b2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4631"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(th1_series_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c221cc59-e60f-40b3-81a0-4241cf18d8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4326"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### probably not capturing []:[tgt] in th2\n",
    "\n",
    "len(th2_series_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdfa57b-c14c-4ffb-9e23-0755640b1a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1515f2-dd2f-4611-829f-6aa1f402d0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a5ece5-d1f5-48b5-a1f3-244b8c251702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28240105-1c57-4f2f-afa1-6b7182833e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### With HTML ###\n",
    "\n",
    "# import pandas as pd\n",
    "# from IPython.display import display, HTML\n",
    "\n",
    "# '''\n",
    "# https://stackoverflow.com/questions/40990700/pandas-dataframes-in-jupyter-columns-of-equal-width-and-centered\n",
    "# https://stackoverflow.com/questions/34322448/pretty-printing-newlines-inside-a-string-in-a-pandas-dataframe\n",
    "# '''\n",
    "\n",
    "# data = [\n",
    "#        {'Greek': \"ὃς δ᾽ ἂν ὑμῶν παραμείνῃ, ὁρῶν ὃν τρόπον ἡμεῖς τάς τε δίκας δικάζομεν καὶ τἆλλα τὴν πόλιν διοικοῦμεν, ἤδη φαμὲν τοῦτον ὡμολογηκέναι ἔργῳ ἡμῖν ἃ ἂν ἡμεῖς κελεύωμεν ποιήσειν ταῦτα, καὶ τὸν μὴ πειθόμενον τριχῇ φαμεν ἀδικεῖν, ὅτι τε γεννηταῖς οὖσιν ἡμῖν οὐ πείθεται, καὶ ὅτι τροφεῦσι, καὶ ὅτι ὁμολογήσας ἡμῖν πείσεσθαι οὔτε πείθεται οὔτε πείθει ἡμᾶς, εἰ μὴ καλῶς τι ποιοῦμεν, προτιθέντων ἡμῶν καὶ οὐκ ἀγρίως ἐπιταττόντων ποιεῖν ἃ ἂν κελεύωμεν, ἀλλὰ ἐφιέντων δυοῖν θάτερα, ἢ πείθειν ἡμᾶς ἢ ποιεῖν, τούτων οὐδέτερα ποιεῖ.\", 'Fowler': '[0] But we say that whoever of you stays here, seeing how we administer justice and how we govern the state in other respects, has thereby entered into an agreement with us to do what we command;\\n[1] and we say that he who does not obey does threefold wrong, because he disobeys us who are his parents, because he disobeys us who nurtured him, and because after agreeing to obey us he neither obeys us nor convinces us that we are wrong, though we give him the opportunity and do not roughly order him to do what we command, but when we allow him a choice of two things, either to convince us of error or to do our bidding, he does neither of these things.”', 'Jowett': '[0] But he who has experience of the manner in which we order justice and administer the State, and still remains, has entered into an implied contract that he will do as we command him.\\n[1] And he who disobeys us is, as we maintain, thrice wrong:\\n[2] first, because in disobeying us he is disobeying his parents;\\n[3] secondly, because we are the authors of his education;\\n[4] thirdly, because he has made an agreement with us that he will duly obey our commands;\\n[5] and he neither obeys them nor convinces us that our commands are wrong;\\n[6] and we do not rudely impose them, but give him the alternative of obeying or convincing us;'},\n",
    "#     {'Greek': 'ταύταις δή φαμεν καὶ σέ, ὦ Σώκρατες, ταῖς αἰτίαις ἐνέξεσθαι, εἴπερ ποιήσεις ἃ ἐπινοεῖς, καὶ οὐχ ἥκιστα Ἀθηναίων σέ, ἀλλ᾽ ἐν τοῖς μάλιστα.', 'Fowler':'[2] and we say that he who does not obey does threefold wrong, because he disobeys us who are his parents, because he disobeys us who nurtured him, and because after agreeing to obey us he neither obeys us nor convinces us that we are wrong, though we give him the opportunity and do not roughly order him to do what we command, but when we allow him a choice of two things, either to convince us of error or to do our bidding, he does neither of these things.”', 'Jowett':'[7] that is what we offer and he does neither.\\n[8] These are the sort of accusations to which, as we were saying, you, Socrates, will be exposed if you accomplish your intentions;\\n[9] you, above all other Athenians.\"'}\n",
    "#        ]\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# d = dict(selector=\"th\",\n",
    "#     props=[('text-align', 'center')])\n",
    "# df.style.set_properties(**{'width':'30em', 'text-align':'left', 'white-space': 'pre-wrap'})\\\n",
    "#         .set_table_styles([d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b4463-9fe6-4b73-a161-c399b729499c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
