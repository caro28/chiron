{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2123425a-0658-4d31-8858-8e44dd272cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import json\n",
    "from functions import load_txt_as_lst, read_alignments\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f2a17-abdd-4056-83cc-aa0fe0821031",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# TEST: Run labse on every sents file in input directory, then write to scratch\n",
    "Moved to .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b65a0be-13c1-4add-b26f-e0f2845887a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urn:cts:greekLit:tlg0001.tlg001\n"
     ]
    }
   ],
   "source": [
    "sents_dir = \"/home/craig.car/repos/chiron/chironata/data/src_data/\"\n",
    "for sents_path in glob.iglob(sents_dir+\"*.sents\"):\n",
    "    print(os.path.splitext(os.path.basename(sents_path))[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81808dad-1338-4e07-b12d-24db2ad1baf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aeschylus_1863\n"
     ]
    }
   ],
   "source": [
    "sents_dir = \"/home/craig.car/repos/chiron/chironata/data/french_trans-dev/\"\n",
    "for sents_path in glob.iglob(sents_dir+\"*.sents\"):\n",
    "    print(os.path.splitext(os.path.basename(sents_path))[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a4e7dda-bb69-4821-af31-a9af46c89484",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_dir = \"/home/craig.car/repos/chiron/chironata/data/src_data/\"\n",
    "dir_out = \"/scratch/craig.car/sents_embeds/src_embeds/\"\n",
    "    \n",
    "for sents_path in glob.iglob(sents_dir+\"*.sents\"):\n",
    "    filename = os.path.splitext(os.path.basename(sents_path))[0]\n",
    "    if os.path.isfile(dir_out+filename+\".emb\") == False:\n",
    "        print(filename)\n",
    "        txt_lst = load_txt_as_lst(sents_path)\n",
    "        # labse_embeds = build_embeddings_huggingface(txt_lst, model)\n",
    "        print(\"built embeds\")\n",
    "        path_out = dir_out+filename+\".emb\"\n",
    "        # write_to_file(labse_embeds,path_out)\n",
    "        print(path_out)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2390d1da-764b-46df-b7c0-9b7987fa5f9d",
   "metadata": {},
   "source": [
    "# Run sentence retrieval and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eb418ed-d72a-4f4d-b6e8-2f1d2c244787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sim_matrix_cosine(src_embeds, tgt_embeds):\n",
    "    # using cosine sim\n",
    "    return cosine_similarity(src_embeds, tgt_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e4a2877-fdb4-4adb-b7bf-790e33c309bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lookup table\n",
    "lookup_path = \"/home/craig.car/repos/chiron/chironata/data/cts_lookup_table.json\"\n",
    "with open(lookup_path) as f:\n",
    "    lookup = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aae5af8-b432-4691-9ad4-6455e0c98ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demosthenes_1_1863',\n",
       " 'demosthenes_1856_1',\n",
       " 'demosthenes_aeschynes_1861',\n",
       " 'demosthenes_2_1861']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup[\"urn:cts:greekLit:tlg0026.tlg003\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87c321aa-eb89-404b-bf46-20a2f211c259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709\n"
     ]
    }
   ],
   "source": [
    "fr_embed_dir = \"/scratch/craig.car/sents_embeds/fr_embeds/\"\n",
    "de_embed_dir = \"/scratch/craig.car/sents_embeds/de_embeds/\"\n",
    "en_embed_dir = \"/scratch/craig.car/sents_embeds/en_embeds/\"\n",
    "it_embed_dir = \"/scratch/craig.car/sents_embeds/it_embeds/\"\n",
    "align_dir = \"/home/craig.car/repos/chiron/chironata/data/alignments_rslts/\"\n",
    "text_dicts_dir = \"/home/craig.car/repos/chiron/chironata/sentence_aligned_texts/\"\n",
    "eval_data_dir = \"/home/craig.car/repos/chiron/chironata/eval_datafiles/\"\n",
    "\n",
    "dim = 768\n",
    "\n",
    "src_embeds_dir = \"/scratch/craig.car/sents_embeds/src_embeds/\"\n",
    "corpus_len = len([name for name in os.listdir(src_embeds_dir) if os.path.isfile(os.path.join(src_embeds_dir, name))])\n",
    "print(corpus_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a162abcd-56a2-41e3-a1b8-55f616f86a42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on /scratch/craig.car/sents_embeds/src_embeds/urn:cts:greekLit:tlg0019.tlg003.emb\n",
      "urn:cts:greekLit:tlg0019.tlg003\n",
      "['Aristophanes_1_1855-1885', 'aristophanes_1_1858', 'aristophanes_1_1915', 'aristophanes_2_1915', 'aristophanes_3_1830', 'aristophanes_1881_1', 'aristophanes_1_1830', 'greekDramas_1912', 'aristophanes_1873', 'tlg0019.tlg003.ogl-eng2.xml', 'Aristophanes_2_1855-1885', 'aristophanes_1907_1']\n",
      "working on Aristophanes_1_1855-1885 translation\n",
      "tgt lang is de\n",
      "top 10 is 139\n",
      "top 1 by transl is 0.059548254620123205\n",
      "top 5 by transl is 0.09958932238193019\n",
      "top 10 by transl is 0.14271047227926079\n",
      "text top 10 is 0.011892539356605066\n",
      "working on aristophanes_1_1858 translation\n",
      "tgt lang is en\n",
      "top 10 is 586\n",
      "top 1 by transl is 0.34394250513347024\n",
      "top 5 by transl is 0.5102669404517454\n",
      "top 10 by transl is 0.6016427104722792\n",
      "text top 10 is 0.06202943189596167\n",
      "working on aristophanes_1_1915 translation\n",
      "tgt lang is it\n",
      "top 10 is 47\n",
      "top 1 by transl is 0.006160164271047228\n",
      "top 5 by transl is 0.027720739219712527\n",
      "top 10 by transl is 0.048254620123203286\n",
      "text top 10 is 0.06605065023956194\n",
      "working on aristophanes_2_1915 translation\n",
      "tgt lang is it\n",
      "top 10 is 182\n",
      "top 1 by transl is 0.08521560574948665\n",
      "top 5 by transl is 0.1540041067761807\n",
      "top 10 by transl is 0.1868583162217659\n",
      "text top 10 is 0.08162217659137577\n",
      "working on aristophanes_3_1830 translation\n",
      "tgt lang is fr\n",
      "top 10 is 52\n",
      "top 1 by transl is 0.004106776180698152\n",
      "top 5 by transl is 0.026694045174537988\n",
      "top 10 by transl is 0.053388090349075976\n",
      "text top 10 is 0.08607118412046544\n",
      "working on aristophanes_1881_1 translation\n",
      "tgt lang is de\n",
      "top 10 is 48\n",
      "top 1 by transl is 0.00513347022587269\n",
      "top 5 by transl is 0.033880903490759756\n",
      "top 10 by transl is 0.049281314168377825\n",
      "text top 10 is 0.0901779603011636\n",
      "working on aristophanes_1_1830 translation\n",
      "tgt lang is fr\n",
      "top 10 is 361\n",
      "top 1 by transl is 0.18993839835728954\n",
      "top 5 by transl is 0.31006160164271046\n",
      "top 10 by transl is 0.37063655030800824\n",
      "text top 10 is 0.12106433949349761\n",
      "working on greekDramas_1912 translation\n",
      "tgt lang is en\n",
      "top 10 is 505\n",
      "top 1 by transl is 0.3162217659137577\n",
      "top 5 by transl is 0.44969199178644764\n",
      "top 10 by transl is 0.5184804928131417\n",
      "text top 10 is 0.16427104722792607\n",
      "working on aristophanes_1873 translation\n",
      "tgt lang is fr\n",
      "top 10 is 332\n",
      "top 1 by transl is 0.18480492813141683\n",
      "top 5 by transl is 0.2915811088295688\n",
      "top 10 by transl is 0.3408624229979466\n",
      "text top 10 is 0.1926762491444216\n",
      "working on tlg0019.tlg003.ogl-eng2 translation\n",
      "tgt lang is en\n",
      "top 10 is 79\n",
      "top 1 by transl is 0.022587268993839837\n",
      "top 5 by transl is 0.055441478439425054\n",
      "top 10 by transl is 0.0811088295687885\n",
      "text top 10 is 0.19943531827515398\n",
      "working on Aristophanes_2_1855-1885 translation\n",
      "tgt lang is de\n",
      "top 10 is 37\n",
      "top 1 by transl is 0.004106776180698152\n",
      "top 5 by transl is 0.019507186858316223\n",
      "top 10 by transl is 0.037987679671457907\n",
      "text top 10 is 0.20260095824777546\n",
      "working on aristophanes_1907_1 translation\n",
      "tgt lang is en\n",
      "top 10 is 60\n",
      "top 1 by transl is 0.008213552361396304\n",
      "top 5 by transl is 0.03182751540041068\n",
      "top 10 by transl is 0.061601642710472276\n",
      "text top 10 is 0.20773442847364815\n",
      "top1 corpus is 0.00014456740316397468\n",
      "top5 corpus is 0.00023627961218285678\n",
      "top10 corpus is 0.00029299637302348115\n"
     ]
    }
   ],
   "source": [
    "src_embeds_dir = \"/scratch/craig.car/sents_embeds/src_embeds/\"\n",
    "corpus_len = len([name for name in os.listdir(src_embeds_dir) if os.path.isfile(os.path.join(src_embeds_dir, name))])\n",
    "corpus_top1 = 0\n",
    "corpus_top5 = 0\n",
    "corpus_top10 = 0\n",
    "\n",
    "for src_embed_path in [\"/scratch/craig.car/sents_embeds/src_embeds/urn:cts:greekLit:tlg0019.tlg003.emb\"]:\n",
    "# for src_embed_path in glob.iglob(src_embeds_dir+\"*.emb\"):\n",
    "    src_eval_data_dict = {}\n",
    "    print(f\"working on {src_embed_path}\")\n",
    "    text_top1 = 0\n",
    "    text_top5 = 0\n",
    "    text_top10 = 0\n",
    "    # get embeds and resize\n",
    "    src_embeddings = np.fromfile(src_embed_path, dtype=np.float32, count=-1)\n",
    "    src_embeddings.resize(src_embeddings.shape[0] // dim, dim)\n",
    "    # print(f\"shape of src embeds {src_embeddings.shape}\")\n",
    "    # save num of src sents to src_eval data dict\n",
    "    src_eval_data_dict[\"num_src_sents\"] = src_embeddings.shape[0]\n",
    "    # get translations\n",
    "    ctsurn = os.path.splitext(os.path.basename(src_embed_path))[0]\n",
    "    print(ctsurn)\n",
    "    translations = lookup[ctsurn]\n",
    "    print(translations)\n",
    "    # for score denominators (reduce if encounter a translation with no rslts)\n",
    "    num_transl = len(translations)\n",
    "    # get text data dict\n",
    "    text_json_path = text_dicts_dir+ctsurn+\".json\"\n",
    "    with open(text_json_path) as f:\n",
    "        text_json = json.load(f)\n",
    "    for tgt_text in translations:\n",
    "        if tgt_text.endswith(\".xml\"):\n",
    "            tgt_text = tgt_text.split(\".xml\")[0]\n",
    "        transl_eval_dict = {}\n",
    "        print(f\"working on {tgt_text} translation\")\n",
    "        # count scores per translation\n",
    "        top_1 = 0\n",
    "        top_5 = 0\n",
    "        top_10 = 0\n",
    "        num_nulls = 0\n",
    "        # get embed file using lang in text_json\n",
    "        if tgt_text not in text_json.keys():\n",
    "            continue\n",
    "        else:\n",
    "            tgt_lang = text_json[tgt_text][\"tgt_lang\"]\n",
    "            transl_eval_dict[\"tgt_lang\"] = tgt_lang\n",
    "            print(f\"tgt lang is {tgt_lang}\")\n",
    "            # if os.path.isfile(de_embed_dir+tgt_text+\".emb\"):\n",
    "            if tgt_lang == \"de\":\n",
    "                tgt_embed = de_embed_dir+tgt_text+\".emb\"\n",
    "            # elif os.path.isfile(en_embed_dir+tgt_text+\".emb\"):\n",
    "            elif tgt_lang == \"en\":\n",
    "                tgt_embed = en_embed_dir+tgt_text+\".emb\"\n",
    "            # elif os.path.isfile(it_embed_dir+tgt_text+\".emb\"):\n",
    "            elif tgt_lang == \"it\":\n",
    "                tgt_embed = it_embed_dir+tgt_text+\".emb\"\n",
    "            # elif os.path.isfile(fr_embed_dir+tgt_text+\".emb\"):\n",
    "            elif tgt_lang == \"fr\":\n",
    "                tgt_embed = fr_embed_dir+tgt_text+\".emb\"\n",
    "            # get tgt embeds\n",
    "            tgt_embeddings = np.fromfile(tgt_embed, dtype=np.float32, count=-1)\n",
    "            tgt_embeddings.resize(tgt_embeddings.shape[0] // dim, dim)\n",
    "            # print(f\"shape of tgt embeds {tgt_embeddings.shape}\")\n",
    "            # build sim matrix\n",
    "            sim_matrix = compute_sim_matrix_cosine(src_embeddings, tgt_embeddings)\n",
    "            # iterate through src sents, compare sim score (src_sent,pred_sent) to top 1,5,10 scores\n",
    "            for src_idx, src_sent_vector in enumerate(sim_matrix):\n",
    "                # print(f\"len of src sent vector is {len(src_sent_vector)}, src idx is {src_idx}\")\n",
    "                # skip translations that were deleted\n",
    "                if tgt_text not in text_json.keys():\n",
    "                    # back out from len of translations\n",
    "                    num_transl -= 1\n",
    "                else:\n",
    "                    pred_sents_idx = text_json[tgt_text][\"aligns_idx\"][str(src_idx)]\n",
    "                    # print(pred_sents_idx)\n",
    "                    # sort vector of sim scores\n",
    "                    sorted_sim_vec = np.flip(np.sort(src_sent_vector))\n",
    "                    # check for each pred_sent in pred_sents\n",
    "                    for tgt_sent_idx in pred_sents_idx:\n",
    "                        if tgt_sent_idx == \"null\":\n",
    "                            num_nulls += 1\n",
    "                            continue\n",
    "                        else:\n",
    "                            tgt_sent_simscore = src_sent_vector[tgt_sent_idx]\n",
    "                            if tgt_sent_simscore >= sorted_sim_vec[0]:\n",
    "                                # print(\"have top 1\")\n",
    "                                top_1 += 1\n",
    "                                top_5 += 1\n",
    "                                top_10 += 1\n",
    "                                continue\n",
    "                            elif tgt_sent_simscore >= sorted_sim_vec[4]:\n",
    "                                # print(\"have top 5\")\n",
    "                                top_5 += 1\n",
    "                                top_10 += 1\n",
    "                                continue    \n",
    "                            elif tgt_sent_simscore >= sorted_sim_vec[9]:\n",
    "                                top_10 += 1\n",
    "                                # print(\"have top 10\")\n",
    "                                continue\n",
    "        \n",
    "        # how many src sents have a pred that's in top 1, top 5, top 10? Don't back out num_nulls from denominator bc no src sent should be aligned to null\n",
    "        top_1_transl = top_1/sim_matrix.shape[0]\n",
    "        top_5_transl = top_5/sim_matrix.shape[0]\n",
    "        top_10_transl = top_10/sim_matrix.shape[0]\n",
    "        print(f\"top 10 is {top_10}\")\n",
    "        print(f\"top 1 by transl is {top_1_transl}\")\n",
    "        print(f\"top 5 by transl is {top_5_transl}\")\n",
    "        print(f\"top 10 by transl is {top_10_transl}\")\n",
    "        transl_eval_dict[\"transl_top1\"] = top_1_transl\n",
    "        transl_eval_dict[\"transl_top5\"] = top_5_transl\n",
    "        transl_eval_dict[\"transl_top10\"] = top_10_transl\n",
    "        transl_eval_dict[\"num_nulls\"] = num_nulls\n",
    "        transl_eval_dict[\"num_tgt_sents\"] = tgt_embeddings.shape[0]\n",
    "        # add to src_eval_data_dict\n",
    "        src_eval_data_dict[tgt_text] = transl_eval_dict\n",
    "        \n",
    "        # add to text-level average\n",
    "        text_top1 += top_1_transl/num_transl\n",
    "        text_top5 += top_5_transl/num_transl\n",
    "        text_top10 += top_10_transl/num_transl\n",
    "        print(f\"text top 10 is {text_top10}\")\n",
    "        \n",
    "    src_eval_data_dict[\"num_translations\"] = num_transl\n",
    "    src_eval_data_dict[\"text_top1\"] = text_top1\n",
    "    src_eval_data_dict[\"text_top5\"] = text_top5\n",
    "    src_eval_data_dict[\"text_top10\"] = text_top10\n",
    "    \n",
    "    # write to json\n",
    "    path_out = eval_data_dir+ctsurn+\".json\"\n",
    "    with open(path_out, 'w') as fp:\n",
    "        json.dump(src_eval_data_dict, fp, ensure_ascii=False)\n",
    "\n",
    "    # add to corpus-level average\n",
    "    corpus_top1 += text_top1/corpus_len\n",
    "    corpus_top5 += text_top5/corpus_len\n",
    "    corpus_top10 += text_top10/corpus_len\n",
    "\n",
    "print(f\"top1 corpus is {corpus_top1}\")\n",
    "print(f\"top5 corpus is {corpus_top5}\")\n",
    "print(f\"top10 corpus is {corpus_top10}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "406dd87b-01fc-4793-b527-e14e184ec295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_src_sents': 974,\n",
       " 'Aristophanes_1_1855-1885': {'tgt_lang': 'de',\n",
       "  'transl_top1': 0.059548254620123205,\n",
       "  'transl_top5': 0.09958932238193019,\n",
       "  'transl_top10': 0.14271047227926079,\n",
       "  'num_nulls': 0,\n",
       "  'num_tgt_sents': 5841},\n",
       " 'aristophanes_1_1858': {'tgt_lang': 'en',\n",
       "  'transl_top1': 0.34394250513347024,\n",
       "  'transl_top5': 0.5102669404517454,\n",
       "  'transl_top10': 0.6016427104722792,\n",
       "  'num_nulls': 0,\n",
       "  'num_tgt_sents': 10625},\n",
       " 'aristophanes_1_1915': {'tgt_lang': 'it',\n",
       "  'transl_top1': 0.006160164271047228,\n",
       "  'transl_top5': 0.027720739219712527,\n",
       "  'transl_top10': 0.048254620123203286,\n",
       "  'num_nulls': 0,\n",
       "  'num_tgt_sents': 2665},\n",
       " 'aristophanes_2_1915': {'tgt_lang': 'it',\n",
       "  'transl_top1': 0.08521560574948665,\n",
       "  'transl_top5': 0.1540041067761807,\n",
       "  'transl_top10': 0.1868583162217659,\n",
       "  'num_nulls': 2,\n",
       "  'num_tgt_sents': 3069},\n",
       " 'aristophanes_3_1830': {'tgt_lang': 'fr',\n",
       "  'transl_top1': 0.004106776180698152,\n",
       "  'transl_top5': 0.026694045174537988,\n",
       "  'transl_top10': 0.053388090349075976,\n",
       "  'num_nulls': 0,\n",
       "  'num_tgt_sents': 4330},\n",
       " 'aristophanes_1881_1': {'tgt_lang': 'de',\n",
       "  'transl_top1': 0.00513347022587269,\n",
       "  'transl_top5': 0.033880903490759756,\n",
       "  'transl_top10': 0.049281314168377825,\n",
       "  'num_nulls': 0,\n",
       "  'num_tgt_sents': 10289},\n",
       " 'aristophanes_1_1830': {'tgt_lang': 'fr',\n",
       "  'transl_top1': 0.18993839835728954,\n",
       "  'transl_top5': 0.31006160164271046,\n",
       "  'transl_top10': 0.37063655030800824,\n",
       "  'num_nulls': 2,\n",
       "  'num_tgt_sents': 2544},\n",
       " 'greekDramas_1912': {'tgt_lang': 'en',\n",
       "  'transl_top1': 0.3162217659137577,\n",
       "  'transl_top5': 0.44969199178644764,\n",
       "  'transl_top10': 0.5184804928131417,\n",
       "  'num_nulls': 0,\n",
       "  'num_tgt_sents': 8924},\n",
       " 'aristophanes_1873': {'tgt_lang': 'fr',\n",
       "  'transl_top1': 0.18480492813141683,\n",
       "  'transl_top5': 0.2915811088295688,\n",
       "  'transl_top10': 0.3408624229979466,\n",
       "  'num_nulls': 3,\n",
       "  'num_tgt_sents': 14269},\n",
       " 'tlg0019.tlg003.ogl-eng2': {'tgt_lang': 'en',\n",
       "  'transl_top1': 0.022587268993839837,\n",
       "  'transl_top5': 0.055441478439425054,\n",
       "  'transl_top10': 0.0811088295687885,\n",
       "  'num_nulls': 859,\n",
       "  'num_tgt_sents': 25},\n",
       " 'Aristophanes_2_1855-1885': {'tgt_lang': 'de',\n",
       "  'transl_top1': 0.004106776180698152,\n",
       "  'transl_top5': 0.019507186858316223,\n",
       "  'transl_top10': 0.037987679671457907,\n",
       "  'num_nulls': 0,\n",
       "  'num_tgt_sents': 5321},\n",
       " 'aristophanes_1907_1': {'tgt_lang': 'en',\n",
       "  'transl_top1': 0.008213552361396304,\n",
       "  'transl_top5': 0.03182751540041068,\n",
       "  'transl_top10': 0.061601642710472276,\n",
       "  'num_nulls': 0,\n",
       "  'num_tgt_sents': 8398},\n",
       " 'num_translations': 12,\n",
       " 'text_top1': 0.10249828884325805,\n",
       " 'text_top5': 0.16752224503764546,\n",
       " 'text_top10': 0.20773442847364815}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_eval_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64ae12ad-56f4-4388-b01d-4fee25883dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 corpus is 0.21721537007984332\n",
      "top5 corpus is 0.3277851981538398\n",
      "top10 corpus is 0.38836388697782265\n"
     ]
    }
   ],
   "source": [
    "print(f\"top1 corpus is {corpus_top1}\")\n",
    "print(f\"top5 corpus is {corpus_top5}\")\n",
    "print(f\"top10 corpus is {corpus_top10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecbcde3-4a65-4093-9889-68efb3eef3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
