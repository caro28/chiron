{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "040e59a6-5dae-4491-b063-2bf107429725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import stanza\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import chain\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2bcac6-1be5-4e2d-aee3-40649e763051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt_as_lst(path_in):\n",
    "    output_lst = []\n",
    "    with open(path_in, \"rt\") as f:\n",
    "        for line in f:\n",
    "            output_lst.append(line)\n",
    "    return output_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a493c89b-9e3c-4e6a-b4bb-eb0446414460",
   "metadata": {},
   "source": [
    "Do differently: use thuc segmented on full string, then use num of tokens to compare back to full text with chapter annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8195df-adf8-44de-9d50-72dbe3feebe9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Greek text from David's file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cec6d72f-fdb5-4663-af95-7db10d29ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathin_thuc = \"/home/craig.car/spring2023/data/cts-sections.jsonl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2233824f-bcaf-4c62-9269-9744df4a5726",
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc_raw = pd.read_json(\n",
    "    pathin_thuc,\n",
    "    lines=True,\n",
    "    compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65e82dbe-651d-4d73-8425-c55618f0e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc_grc_df = thuc_raw.loc[thuc_raw['book']=='urn:cts:greekLit:tlg0003.tlg001.perseus-grc2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cbc511a-d3b2-4737-8602-d699294c2460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>id</th>\n",
       "      <th>loc</th>\n",
       "      <th>seq</th>\n",
       "      <th>text</th>\n",
       "      <th>cites</th>\n",
       "      <th>group</th>\n",
       "      <th>lang</th>\n",
       "      <th>title</th>\n",
       "      <th>translation</th>\n",
       "      <th>wlang</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001:1.1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>Θουκυδίδης Ἀθηναῖος ξυνέγραψε τὸν πόλεμον τῶν\\...</td>\n",
       "      <td>[book, chapter, section]</td>\n",
       "      <td>Thucydides</td>\n",
       "      <td>grc</td>\n",
       "      <td>History of the Peloponnesian War</td>\n",
       "      <td>False</td>\n",
       "      <td>grc</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001:1.1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>κίνησις γὰρ αὕτη μεγίστη δὴ τοῖς Ἕλλησιν ἐγένε...</td>\n",
       "      <td>[book, chapter, section]</td>\n",
       "      <td>Thucydides</td>\n",
       "      <td>grc</td>\n",
       "      <td>History of the Peloponnesian War</td>\n",
       "      <td>False</td>\n",
       "      <td>grc</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001:1.1.3</td>\n",
       "      <td>2</td>\n",
       "      <td>τὰ γὰρ πρὸ αὐτῶν καὶ τὰ ἔτι παλαίτερα σαφῶς μὲ...</td>\n",
       "      <td>[book, chapter, section]</td>\n",
       "      <td>Thucydides</td>\n",
       "      <td>grc</td>\n",
       "      <td>History of the Peloponnesian War</td>\n",
       "      <td>False</td>\n",
       "      <td>grc</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001:1.2.1</td>\n",
       "      <td>3</td>\n",
       "      <td>φαίνεται γὰρ ἡ νῦν Ἑλλὰς καλουμένη οὐ πάλαι βε...</td>\n",
       "      <td>[book, chapter, section]</td>\n",
       "      <td>Thucydides</td>\n",
       "      <td>grc</td>\n",
       "      <td>History of the Peloponnesian War</td>\n",
       "      <td>False</td>\n",
       "      <td>grc</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001:1.2.2</td>\n",
       "      <td>4</td>\n",
       "      <td>τῆς γὰρ ἐμπορίας οὐκ οὔσης, οὐδ’ ἐπιμειγνύντες...</td>\n",
       "      <td>[book, chapter, section]</td>\n",
       "      <td>Thucydides</td>\n",
       "      <td>grc</td>\n",
       "      <td>History of the Peloponnesian War</td>\n",
       "      <td>False</td>\n",
       "      <td>grc</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           book  \\\n",
       "0  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2   \n",
       "1  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2   \n",
       "2  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2   \n",
       "3  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2   \n",
       "4  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2   \n",
       "\n",
       "                                                  id  \\\n",
       "0  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...   \n",
       "1  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...   \n",
       "2  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...   \n",
       "3  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...   \n",
       "4  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...   \n",
       "\n",
       "                                     loc  seq  \\\n",
       "0  urn:cts:greekLit:tlg0003.tlg001:1.1.1    0   \n",
       "1  urn:cts:greekLit:tlg0003.tlg001:1.1.2    1   \n",
       "2  urn:cts:greekLit:tlg0003.tlg001:1.1.3    2   \n",
       "3  urn:cts:greekLit:tlg0003.tlg001:1.2.1    3   \n",
       "4  urn:cts:greekLit:tlg0003.tlg001:1.2.2    4   \n",
       "\n",
       "                                                text  \\\n",
       "0  Θουκυδίδης Ἀθηναῖος ξυνέγραψε τὸν πόλεμον τῶν\\...   \n",
       "1  κίνησις γὰρ αὕτη μεγίστη δὴ τοῖς Ἕλλησιν ἐγένε...   \n",
       "2  τὰ γὰρ πρὸ αὐτῶν καὶ τὰ ἔτι παλαίτερα σαφῶς μὲ...   \n",
       "3  φαίνεται γὰρ ἡ νῦν Ἑλλὰς καλουμένη οὐ πάλαι βε...   \n",
       "4  τῆς γὰρ ἐμπορίας οὐκ οὔσης, οὐδ’ ἐπιμειγνύντες...   \n",
       "\n",
       "                      cites       group lang  \\\n",
       "0  [book, chapter, section]  Thucydides  grc   \n",
       "1  [book, chapter, section]  Thucydides  grc   \n",
       "2  [book, chapter, section]  Thucydides  grc   \n",
       "3  [book, chapter, section]  Thucydides  grc   \n",
       "4  [book, chapter, section]  Thucydides  grc   \n",
       "\n",
       "                              title  translation wlang  \\\n",
       "0  History of the Peloponnesian War        False   grc   \n",
       "1  History of the Peloponnesian War        False   grc   \n",
       "2  History of the Peloponnesian War        False   grc   \n",
       "3  History of the Peloponnesian War        False   grc   \n",
       "4  History of the Peloponnesian War        False   grc   \n",
       "\n",
       "                              work  \n",
       "0  urn:cts:greekLit:tlg0003.tlg001  \n",
       "1  urn:cts:greekLit:tlg0003.tlg001  \n",
       "2  urn:cts:greekLit:tlg0003.tlg001  \n",
       "3  urn:cts:greekLit:tlg0003.tlg001  \n",
       "4  urn:cts:greekLit:tlg0003.tlg001  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thuc_grc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ccbafc7-34f5-4426-8353-86924ad539a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>τοιαῦτα μὲν οἱ Κερκυραῖοι εἶπον: οἱ δὲ Κορίνθι...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "132  τοιαῦτα μὲν οἱ Κερκυραῖοι εἶπον: οἱ δὲ Κορίνθι..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thuc_grc_df.loc[thuc_grc_df[\"loc\"]==\"urn:cts:greekLit:tlg0003.tlg001:1.36.4\", [\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4b32b20-e057-4cc6-9e9d-56ed3ea7d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc_grc_series = thuc_grc_df['text'].replace('\\n',' ', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a76c9445-c05c-4389-a97e-ad58dad6fe61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'τοιαῦτα μὲν οἱ Κερκυραῖοι εἶπον: οἱ δὲ Κορίνθιοι μετ’ αὐτοὺς τοιάδε.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thuc_grc_series[132]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd295487-b9cc-4c46-935c-7b782e919c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_txt(txt_series):\n",
    "    '''\n",
    "    Conveinplace= to str (in case of NaN present as float) and concatenates rows \n",
    "    into one continuous string\n",
    "    '''\n",
    "    # convert all rows to string\n",
    "    txt_series = txt_series.apply(str)\n",
    "    # join into a single string\n",
    "    return ' '.join(txt_series)\n",
    "\n",
    "def split_txt(txt_str, lang):\n",
    "    if lang=='en':\n",
    "        # split keeping split char\n",
    "        split_lst = re.split(\"([;:])\", txt_str)\n",
    "        delimiters = \";:\"\n",
    "    else:\n",
    "        split_lst = re.split(\"([;:.])\", txt_str)\n",
    "        delimiters = \";:.\"\n",
    "    delete_idx = []\n",
    "    for idx, token in enumerate(split_lst):\n",
    "        if token in delimiters:\n",
    "            split_lst[idx-1] = split_lst[idx-1]+split_lst[idx]\n",
    "            delete_idx.append(idx)\n",
    "    for index in sorted(delete_idx, reverse=True):\n",
    "        del split_lst[index]\n",
    "    return split_lst\n",
    "\n",
    "def run_stanza(en_str):\n",
    "    '''\n",
    "    returns sentences as list\n",
    "    '''\n",
    "    # load stanza model for en\n",
    "    nlp = stanza.Pipeline(lang='en', processors='tokenize')\n",
    "    doc = nlp(en_str)\n",
    "    return [sentence.text for sentence in doc.sentences]\n",
    "\n",
    "def flatten_list(nested_list):\n",
    "    return list(chain.from_iterable(nested_list))\n",
    "\n",
    "def segment_series(txt_series, lang):\n",
    "    '''\n",
    "    Modified from segment_en in preprocess_functions.py:\n",
    "        uses split_txt function (works for en or el)\n",
    "        removes text between % (Faroosh's comments)\n",
    "    '''\n",
    "    # join into one str\n",
    "    series_str = concatenate_txt(txt_series)\n",
    "    if lang == 'el':\n",
    "        # remove \"\\n\" from text\n",
    "        \n",
    "        # split on ;:. for el\n",
    "        return split_txt(series_str, lang)\n",
    "    # TODO: update split_txt() for German and Persian\n",
    "    else:\n",
    "        # run stanza\n",
    "        series_sents = run_stanza(series_str)\n",
    "        # split further on ;:\n",
    "        series_split = []\n",
    "        for sent in series_sents:\n",
    "            series_split.append(split_txt(sent, lang))\n",
    "        return flatten_list(series_split)\n",
    "\n",
    "def preprocess_series(txt_series, lang, keep_speaker_label, speaker_label_names):\n",
    "    # convert all rows to string\n",
    "    txt_series = txt_series.apply(str)\n",
    "    # remove whitespace at beginning and end\n",
    "    txt_series = txt_series.str.strip()\n",
    "    # remove speaker labels if present\n",
    "    # TODO: simpler way to do this?\n",
    "    if keep_speaker_label == False:\n",
    "        if lang == 'el':\n",
    "            for idx, item in enumerate(txt_series):\n",
    "                if item.startswith('Σωκράτης.'):\n",
    "                    txt_series.loc[idx] = txt_series.loc[idx].lstrip('Σωκράτης.')\n",
    "                elif item.startswith('Κρίτων.'):\n",
    "                    txt_series.loc[idx] = txt_series.loc[idx].lstrip('Κρίτων.')\n",
    "        else:\n",
    "            for idx, item in enumerate(txt_series):\n",
    "                if txt_series.loc[idx].startswith(speaker_label_names[0]):\n",
    "                    txt_series.loc[idx] = txt_series.loc[idx].lstrip(speaker_label_names[0])\n",
    "                elif txt_series.loc[idx].startswith(speaker_label_names[1]):\n",
    "                    txt_series.loc[idx] = txt_series.loc[idx].lstrip(speaker_label_names[1])\n",
    "        # remove whitespace at beginning and end\n",
    "        txt_series = txt_series.str.strip()\n",
    "    # split text into sentences\n",
    "    series_split = segment_series(txt_series, lang)\n",
    "    \n",
    "    # save as df and change col name\n",
    "    series_df = pd.DataFrame(series_split)\n",
    "    series_df.columns = ['text']\n",
    "    # remove whitespace at beginning and end\n",
    "    series_df['text'] = series_df['text'].str.strip()\n",
    "    # drop rows with NaN\n",
    "    series_df.dropna(how='any', inplace=True)\n",
    "    # # drop rows with empty strings\n",
    "    # series_df.drop(series_df.loc[series_df['text']==''].index, inplace=True)\n",
    "    # send to list\n",
    "    series_lst = list(series_df['text'])\n",
    "\n",
    "    return series_lst\n",
    "    # return series_split\n",
    "\n",
    "def write_file(input_lst, name_out):\n",
    "    filename = name_out\n",
    "    with open(filename, 'w') as file:\n",
    "        for sentence in input_lst:\n",
    "            file.write(f\"{sentence}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30481408-1296-4228-a5c5-3a5678c0e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc_grc_series = thuc_grc_df['text'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab3ed53d-cdc3-45b7-bd57-1e4b1211a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc_grc_series = thuc_grc_series.replace('\\n',' ', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e633256b-5612-4b72-a76b-81d501a2e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc_grk_processed = preprocess_series(thuc_grc_series, \"el\",\n",
    "                                       True, None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7700ece7-8708-4295-a168-cd988d6abfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ' and ] back to end of sentence they belong to (moved to next sentence by sentence splitting on .)\n",
    "for idx, sent in enumerate(thuc_grk_processed):\n",
    "    if sent.startswith(\"’ \"):\n",
    "        thuc_grk_processed[idx-1] += \"’\"\n",
    "        thuc_grk_processed[idx] = thuc_grk_processed[idx][2:]\n",
    "    elif sent.startswith(\"]\"):\n",
    "        thuc_grk_processed[idx-1] += \"]\"\n",
    "        thuc_grk_processed[idx] = thuc_grk_processed[idx][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dd71dd8-f6d3-4289-b8a4-a5d401cd0812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6098"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thuc_grk_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "d1ff5974-47a3-4727-9b62-dd0ca556469b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ὅταν ὁ μετὰ τοῦτο τὸ θέρος χειμὼν τελευτήσῃ, ἓν καὶ εἰκοστὸν ἔτος πληροῦται.]'"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete last row (empty)\n",
    "thuc_grk_processed[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "7318b91d-905d-433c-b03f-154cb7170911",
   "metadata": {},
   "outputs": [],
   "source": [
    "del thuc_grk_processed[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "d76cb8ab-51ba-43d7-9685-2a08f636aaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6097"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thuc_grk_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "00f05f38-e8ce-4239-92f3-beb6e7e9d7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ὅταν ὁ μετὰ τοῦτο τὸ θέρος χειμὼν τελευτήσῃ, ἓν καὶ εἰκοστὸν ἔτος πληροῦται.]'"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thuc_grk_processed[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69f92321-79a0-432c-ad66-b3aa30aeb8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sent in enumerate(thuc_grk_processed):\n",
    "    thuc_grk_processed[idx] = thuc_grk_processed[idx].replace(\" .\", \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6502789-83c6-44ef-aefc-8985774116f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ἐκκλησίαν δὲ ποιήσαντας τοὺς στρατηγοὺς καὶ τοὺς πρυτάνεις πρῶτον περὶ τῆς εἰρήνης.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thuc_grk_processed[3279]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "c5d8f6e4-0e45-4c02-ad7a-e2419508bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thuc_grk_processed is original\n",
    "# thuc_grk_processed_1 is after stripping whitespaces\n",
    "# thuc_grk_processed_3 is after moving last ] to previous sent\n",
    "# grk_pathout = \"/home/craig.car/spring2023/data/align_noisy_data/thucydides/thuc_grk_processed_3.txt\"\n",
    "# write_file(thuc_grk_processed, grk_pathout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7970e387-e3b1-434a-a2f2-f1bc006c5afb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Thuc Fr translation: no chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "364637bf-dcce-4a17-a7e5-17626617edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_thuc_fr = \"/home/craig.car/spring2023/data/align_noisy_data/thucydides/thuc_fr_1863_str.txt\"\n",
    "thuc_fr_lst_raw = load_txt_as_lst(path_thuc_fr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd939f3b-4b51-4606-ac80-de1b79b448a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOTICE BIOGRAPHIQUE. \\n',\n",
       " '\\n',\n",
       " 'Les seuls renseignements certains que nous possédions sur la personne de Thucydide se tirent de quelques passages de son livre. Les autres données qui se rencontrent çà et là, notamment dans les deux biographies, dont l’une est attribuée à Marcellinus et l’autre est anonyme, sont d’une date trop récente pour avoir beaucoup d’autorité. Aussi, sans entrer dans des détails d’un intérêt secondaire, nous bornerons-nous à rapporter les circonstances les plus essentielles de la vie de Thucydide, celles qui ont eu quelque influence sur sa carrière d’historien. \\n',\n",
       " '\\n',\n",
       " 'Thucydide s’est nommé en plusieurs endroits de son ouvrage, comme s’il eût craint que le titre ne se perdit. En tête du livre, il prend la qualité de citoyen d’Athènes; une seule fois (Liv. IV, chap. civ), il ajoute à son nom celui de son père Oloros; c’est lorsqu’il se cite luimême en qualité de fonctionnaire public. \\n']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thuc_fr_lst_raw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b228bfe-3e00-4f82-b422-606c12ce8c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOTICE BIOGRAPHIQUE. \\n»'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thuc_fr_lst_raw[0] + \"»\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "109a47d9-bfd5-4ea4-8be7-2547fc55fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc_fr_str = \" \".join(thuc_fr_lst_raw)\n",
    "thuc_fr_str = re.sub(\"« \", \"«\", thuc_fr_str)\n",
    "thuc_fr_str = re.sub(\" »\", \"»\", thuc_fr_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e9bace3-ee35-4244-8486-06753bf10667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_txt(txt_str, lang):\n",
    "    if lang=='el':\n",
    "        split_lst = re.split(\"([;:.])\", txt_str)\n",
    "        delimiters = \";:.\"\n",
    "    else:\n",
    "        # split keeping split char\n",
    "        split_lst = re.split(\"([;:])\", txt_str)\n",
    "        # includes punctuation that caused errors: update for different texts/languages\n",
    "        delimiters = \";:\"        \n",
    "    # add delimiters back to previous token\n",
    "    delete_idx = []\n",
    "    for idx, phrase in enumerate(split_lst):\n",
    "        if phrase in delimiters:\n",
    "            split_lst[idx-1] = split_lst[idx-1]+split_lst[idx]\n",
    "            delete_idx.append(idx)\n",
    "    for index in sorted(delete_idx, reverse=True):\n",
    "        del split_lst[index]\n",
    "    \n",
    "    split_lst_no_newlines = []\n",
    "    for idx, phrase in enumerate(split_lst):\n",
    "        split_lst_no_newlines.extend(phrase.split(\"\\n\"))\n",
    "    # return split_lst\n",
    "    return split_lst_no_newlines\n",
    "\n",
    "def run_stanza(text_str, lang, model_):\n",
    "    '''\n",
    "    returns sentences as list\n",
    "    '''\n",
    "    doc = model_(text_str)\n",
    "    return [sentence.text for sentence in doc.sentences]\n",
    "\n",
    "def flatten_list(nested_list):\n",
    "    return list(chain.from_iterable(nested_list))\n",
    "\n",
    "def segment_series(txt_str, lang, stanza_model):\n",
    "    if lang == 'el':\n",
    "        # split on ;:. for el\n",
    "        return split_txt(txt_str, lang)\n",
    "    else:\n",
    "        # run stanza\n",
    "        series_sents = run_stanza(txt_str, lang, stanza_model)\n",
    "        # split further on ;:\n",
    "        series_split = []\n",
    "        trailing_punct = \"»\"\n",
    "        for sent_idx, sent in enumerate(series_sents):\n",
    "            # if sent in trailing_punct:\n",
    "            #     print(f\"idx is {sent_idx} and sent is {sent}\")\n",
    "            #     print(series_split[-1])\n",
    "            #     series_split[-1][0] = series_split[-1][0]+sent\n",
    "            # else:\n",
    "            new_sent = split_txt(sent, lang)\n",
    "            series_split.append(new_sent)\n",
    "        return flatten_list(series_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66e71f30-d35c-4165-af08-cae4a78efcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_series(txt_str, lang, stanza_model, keep_speaker_label, speaker_label_names):\n",
    "    # split text into sentences\n",
    "    series_split = segment_series(txt_str, lang, stanza_model)\n",
    "    print(\"segmented str into sentences\")\n",
    "    \n",
    "    # save as df and change col name\n",
    "    series_df = pd.DataFrame(series_split)\n",
    "    series_df.columns = ['text']\n",
    "    \n",
    "    # remove whitespace at beginning and end\n",
    "    series_df['text'] = series_df['text'].str.strip()\n",
    "\n",
    "    # drop rows with NaN\n",
    "    series_df.dropna(how='any', inplace=True)\n",
    "\n",
    "    # drop rows with empty strings\n",
    "    series_df.drop(series_df.loc[series_df['text']==''].index, inplace=True)\n",
    "\n",
    "    # send to list\n",
    "    series_lst = list(series_df['text'])\n",
    "\n",
    "    return series_lst\n",
    "    # return series_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ba58c9-43ae-4422-a584-634f41495e83",
   "metadata": {},
   "source": [
    "## Load Stanza\n",
    "To use GPU, from https://github.com/stanfordnlp/stanza/issues/530\n",
    "(Have not done this myself yet - need new env for python version)\n",
    "\n",
    "Environment (please complete the following information):\n",
    "- OS: Ubuntu 20.10\n",
    "- Python version: Python 3.8.5 [GCC 7.3.0] :: Anaconda, Inc. on linux\n",
    "- Stanza version: 1.1.1\n",
    "\n",
    "Additional context\n",
    "- PyTorch installed successfully with conda install pytorch torchvision torchaudio cudatoolkit=11.0 -c pytorch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "0a6ed185-8361-46c9-abfd-8e5151ab7af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 15:14:45 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf8bb65fcf14282b5ac59fa4275fd24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 15:14:45 WARNING: Language fr package default expects mwt, which has been added\n",
      "2023-04-29 15:14:45 INFO: Loading these models for language: fr (French):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "=======================\n",
      "\n",
      "2023-04-29 15:14:45 INFO: Use device: cpu\n",
      "2023-04-29 15:14:45 INFO: Loading: tokenize\n",
      "2023-04-29 15:14:45 INFO: Loading: mwt\n",
      "2023-04-29 15:14:45 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# load stanza model for lang\n",
    "lang_ = \"fr\"\n",
    "stanza_model_ = stanza.Pipeline(lang=lang_, processors='tokenize', use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "03fd25ae-3d2b-4ea0-9b4a-e7fd29265d66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmented str into sentences\n"
     ]
    }
   ],
   "source": [
    "thuc_fr_processed = preprocess_series(thuc_fr_str, \"fr\", stanza_model_,\n",
    "                                      True, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "b2aa4583-9fc1-47fd-bd52-9a2ced2cf19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17267"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thuc_fr_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "a9d5bdb9-d162-4eb5-b470-4584280ac9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add trailing » to previous sentence\n",
    "delete_idx = []\n",
    "trailing_punct = \"»\"\n",
    "for sent_idx, sent in enumerate(thuc_fr_processed):\n",
    "    # if » was split into its own sentence\n",
    "    if sent == trailing_punct:\n",
    "        thuc_fr_processed[sent_idx-1] = thuc_fr_processed[sent_idx-1]+trailing_punct\n",
    "        delete_idx.append(sent_idx)\n",
    "    elif sent.startswith(trailing_punct):\n",
    "        # if » was split to the beginning of the following sentence (followed by whitespace)\n",
    "        thuc_fr_processed[sent_idx-1] = thuc_fr_processed[sent_idx-1]+trailing_punct\n",
    "        thuc_fr_processed[sent_idx] = thuc_fr_processed[sent_idx][1:]\n",
    "for index in sorted(delete_idx, reverse=True):\n",
    "    del thuc_fr_processed[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "5848fd97-781c-4252-bd11-52ea1f9964b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17203"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thuc_fr_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "339b0fef-b348-48af-a8b1-1ac9d5784b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(input_lst, name_out):\n",
    "    filename = name_out\n",
    "    with open(filename, 'w') as file:\n",
    "        for sentence in input_lst:\n",
    "            file.write(f\"{sentence}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "8e371e71-2096-41c2-a5e8-2c886e20d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3 is after adding splitting on newlines at end of split_text()\n",
    "# # 4 is after adding » to preceding token (to avoid splitting onto new line)\n",
    "# # 5 is after moving » that was at start of a sentence to previous sentence\n",
    "# path_out = \"/home/craig.car/spring2023/data/align_noisy_data/thucydides/thuc_fr_1863_processed_5.txt\"\n",
    "# write_file(thuc_fr_processed, path_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4374909-7bac-4ebb-898f-4654163efce4",
   "metadata": {},
   "source": [
    "# Thuc Fr translation: with chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7beff98a-82bd-41d8-9ebb-e27fb4209ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc_fr_chap_raw = \"/home/craig.car/spring2023/data/align_noisy_data/thucydides/thuc_fr_str_with_chapter.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "159b5f69-5ddb-4527-984b-1cbbdc4276f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc_fr_chap_lst = load_txt_as_lst(thuc_fr_chap_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b42bbfd-b9c6-4a28-b87c-c784aa8cb490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOTICE BIOGRAPHIQUE. \\n',\n",
       " '\\n',\n",
       " 'Les seuls renseignements certains que nous possédions sur la personne de Thucydide se tirent de quelques passages de son livre. Les autres données qui se rencontrent çà et là, notamment dans les deux biographies, dont l’une est attribuée à Marcellinus et l’autre est anonyme, sont d’une date trop récente pour avoir beaucoup d’autorité. Aussi, sans entrer dans des détails d’un intérêt secondaire, nous bornerons-nous à rapporter les circonstances les plus essentielles de la vie de Thucydide, celles qui ont eu quelque influence sur sa carrière d’historien. \\n',\n",
       " '\\n',\n",
       " 'Thucydide s’est nommé en plusieurs endroits de son ouvrage, comme s’il eût craint que le titre ne se perdit. En tête du livre, il prend la qualité de citoyen d’Athènes; une seule fois (Liv. IV, chap. civ), il ajoute à son nom celui de son père Oloros; c’est lorsqu’il se cite luimême en qualité de fonctionnaire public. \\n']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thuc_fr_chap_lst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05ba6ece-765f-43a0-a4cc-3dabf2de1991",
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc_fr_chap_str = \" \".join(thuc_fr_chap_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfcabd67-40e3-473b-8332-a4061b0bf40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc_fr_chap_str = re.sub(\"« \", \"«\", thuc_fr_chap_str)\n",
    "thuc_fr_chap_str = re.sub(\" »\", \"»\", thuc_fr_chap_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94a9b14-405f-4f1b-8973-0231330032e6",
   "metadata": {},
   "source": [
    "## Split by section (including chapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ef7f1cd-0125-4dc2-900d-79cb02e18acb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thuc_fr_chap_str_split = thuc_fr_chap_str.split(\"#@$%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87c5dd92-8100-442e-b6e5-be7a4d8b9a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1865"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thuc_fr_chap_str_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d64e299-eaa9-4fe8-9fde-c84e6fb66bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define patterns\n",
    "book_pattern = re.compile(\" book=[0-9] \")\n",
    "chap_pattern = re.compile(\" book=[0-9],chapter=[0-9]+ \")\n",
    "notes_pattern = re.compile(\" section=[0-9] \")\n",
    "index_pattern = re.compile(\" back= \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe69aba-25cd-4108-b480-e666275f0a2e",
   "metadata": {},
   "source": [
    "## logic\n",
    "- If after book_pattern: Book summary and table of contents\n",
    "- If after chap_pattern: Text from chapter number specified in tag\n",
    "- Before book 1: foreward and table of contents. After book=8,chapter=109: notes, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "4881643d-7d2c-41cc-9a67-452fe16e43a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_no_markers = []\n",
    "txt_no_markers.append(thuc_fr_chap_str_split[0])\n",
    "# counter to track idx of txt_no_markers\n",
    "txt_no_markers_counter = 0\n",
    "\n",
    "chap_num_2_idx_thuc_fr_chap_sents = {}\n",
    "idx_thuc_fr_chap_sents_2_section_name = {}\n",
    "idx_thuc_fr_chap_sents_2_section_name[0] = \"foreword\"\n",
    "\n",
    "book_counter = 0\n",
    "chapter_counter = 0\n",
    "notes_book_counter = 0\n",
    "\n",
    "# we know that thuc_fr_chap_str_split[0] is foreword\n",
    "for section_idx, section in enumerate(thuc_fr_chap_str_split[1:]):\n",
    "    # if section is a book marker\n",
    "    if re.match(book_pattern, section) != None:\n",
    "        # increment book counter\n",
    "        book_counter += 1\n",
    "        # reset chapter_counter\n",
    "        chapter_counter = 1\n",
    "        # following section is book introduction and table of contents\n",
    "        # add to txt_no_markers but do not mark as chapter\n",
    "        txt_no_markers.append(thuc_fr_chap_str_split[section_idx+2])\n",
    "        # add to idx_thuc_fr_chap_sents_2_section_name\n",
    "        txt_no_markers_counter += 1\n",
    "        idx_thuc_fr_chap_sents_2_section_name[txt_no_markers_counter] = (\"book \"+str(book_counter)+\" introduction\")\n",
    "        \n",
    "    # if section is a chapter marker\n",
    "    elif re.match(chap_pattern, section) != None:\n",
    "        # following section is chapter text\n",
    "        txt_no_markers.append(thuc_fr_chap_str_split[section_idx+2])\n",
    "        # add to dict b/c is chapter\n",
    "        chap_num = str(book_counter)+\",\"+str(chapter_counter)\n",
    "        chap_num_2_idx_thuc_fr_chap_sents[chap_num] = txt_no_markers_counter\n",
    "        # increment chapter counter\n",
    "        chapter_counter += 1\n",
    "        # update txt_no_markers idx counter\n",
    "        txt_no_markers_counter += 1\n",
    "        idx_thuc_fr_chap_sents_2_section_name[txt_no_markers_counter] = chap_num\n",
    "    \n",
    "    elif re.match(notes_pattern, section) != None:\n",
    "        # following section contains notes per chapter\n",
    "        txt_no_markers.append(thuc_fr_chap_str_split[section_idx+2])\n",
    "        txt_no_markers_counter += 1\n",
    "        notes_book_counter += 1\n",
    "        book_num = str(notes_book_counter)\n",
    "        idx_thuc_fr_chap_sents_2_section_name[txt_no_markers_counter] = \"book \"+book_num+\" notes\"\n",
    "    \n",
    "    elif re.match(index_pattern, section) != None:\n",
    "        # following (and last) section contains index\n",
    "        txt_no_markers.append(thuc_fr_chap_str_split[section_idx+2])\n",
    "        txt_no_markers_counter += 1\n",
    "        idx_thuc_fr_chap_sents_2_section_name[txt_no_markers_counter] = \"index\"\n",
    "    \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "1c7b8975-65e3-4bd9-a69f-f41a46838c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values are idx of chapters\n",
    "chapter_indices = list(chap_num_2_idx_thuc_fr_chap_sents.values())\n",
    "chapter_indices = sorted(chapter_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "4ac55ddc-1a6d-4e70-aeef-f10d7d22df43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3,67'"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_thuc_fr_chap_sents_2_section_name[318]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e95aad59-c251-470b-b2a0-d0f3f3ef3f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent_idx, sent in enumerate(txt_no_markers):\n",
    "    txt_no_markers[sent_idx] = txt_no_markers[sent_idx].replace(\"-·\", \"- ·\")\n",
    "    # txt_no_markers[sent_idx] = txt_no_markers[sent_idx].replace(\".\", \". \")\n",
    "for sent_idx, sent in enumerate(txt_no_markers):\n",
    "    txt_no_markers[sent_idx] = txt_no_markers[sent_idx].replace(\"« \", \"«\")\n",
    "    txt_no_markers[sent_idx] = txt_no_markers[sent_idx].replace(\" »\", \"»\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d0bbfa-7de7-4109-a4cf-d380f297353a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### fix missing whitespace in token 69581"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "55bf4e21-8523-4217-a5ca-21ea2dc609c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_no_markers[318] = ' \\n \\n LXVII. «Nous sommes entrés dans ces détails, ô Lacédëmoniens, afin de motiver à vos yeux la sentence que vous allez rendre, et de légitimer plus encore aux nôtres la vengeance qui nous anime. Ne vous laissez pas attendrir par l’énumération de leurs anciens services, si tant est qu’ils soient réels. Les bienfaits passés peuvent être un moyen de défense pour les victimes d’une injustice; mais ils doivent attirer une double animadversion sur les auteurs d’actes infâmes, parce que leur crime est un démenti donné à leurs mérites précédents. Que leurs doléances et leurs supplications ne leur soient d’aucun secours, non plus que leurs appels aux sépulcres de vos pères et à leur propre abandon. A notre tour, nous évoquerons notre jeunesse impitoyablement massacrée, elle dont les pères sont morts à Goronée pour entraîner dans votre parti la Béotie, ou, vieux et délaissés dans leurs demeures solitaires, vous supplient bien plus fortement de les venger. La pitié n’est due qu’à l’infortune imméritée; une souffrance aussi juste que la leur doit être au contraire un sujet de joie. \\n \\n «Pour ce qui est de leur isolement actuel, ils ne doivent  l’imputer qu’à eux-mêmes. Ils ont sciemment repoussé les meilleurs alliés, foulé aux pieds les plus saintes lois par un esprit de haine plutôt que de justice. Même aujourd’hui la satisfaction qu’ils nous auront donnée ne sera pas équivalente à leur crime; elle sera fixée par la loi, car ce n’est point, comme ils le disent, à la suite d’un combat et les mains étendues qu’ils se sont livrés, mais en vertu d’une convention formelle et en se soumettant à un jugement. \\n \\n «Lacédémoniens, prêtez main forte à la loi des Grecs, qu’ils ont violée; et, comme nous avons souffert de cette violation, récompensez le zèle dont nous avons fait preuve. Qu’il ne soit pas dit que nous avons été supplantés dans votre amitié par la séduction de leurs discours. Montrez’ aux Grecs par un grand exemple qu’à vos yeux le langage ne prévaudra jamais sur les actes : louables, une courte mention leur suffit; coupables, (??)l leur faut de belles phrases pour voile. Mais si des chefs, comme vous aujourd’hui, savent établir contre les coupables des jugements expéditifs, on cherchera moins à pallier des actions criminelles par des discours pompeux.» \\n \\n '\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248097aa-1cc2-4bb7-b0dc-ed38e8d53648",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build dict of sent id to chapter name, using running number of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064275ae-5bae-49af-a6e2-a2c0b5858203",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### TODO: newline splitting no longer necessary? (See new, additional splitting on newlines after split_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3fbec3aa-7bdb-4d25-abef-76bf1a14c495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17203"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thuc_fr_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "198c03c3-c48a-4c50-9ae5-ad791515198b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[<i) TILiJe, 11, Γ» 76 cl 612.']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thuc_fr_processed[246].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "401d5852-61b6-441c-8bee-0f76f9916b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc_fr_processed_splitnewline = []\n",
    "for sent in thuc_fr_processed:\n",
    "    thuc_fr_processed_splitnewline.extend(sent.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f9be9177-eaed-40a1-bd51-8805f587c924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17203"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thuc_fr_processed_splitnewline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bb8124a6-0fc7-4729-9b85-4be75219f22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOTICE', 'BIOGRAPHIQUE.']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thuc_fr_processed_splitnewline[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cf22ce14-a8e0-46a4-81c7-2fa3fa695614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thuc_fr_processed == thuc_fr_processed_splitnewline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e2130b-4af2-4587-ae70-45834ef790f8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Tokenize both docs (thuc_fr_processed and txt_no_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "7fb1aa33-c314-499f-9139-6f498890acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc_sents_tokenized = []\n",
    "for idx, sent in enumerate(thuc_fr_processed):\n",
    "    thuc_sents_tokenized.append(sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "15f78386-ba04-44ae-84d3-0658e0df22cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17203"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thuc_sents_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "1d1b6650-7d98-455c-9b49-00152111d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc_chaps_tokenized = []\n",
    "for idx, sent in enumerate(txt_no_markers):\n",
    "    thuc_chaps_tokenized.append(sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "cbb827a1-6488-417c-89f0-326c1220e46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "933"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thuc_chaps_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d160543d-d2d4-4825-80ad-70420054460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens_sents = 0\n",
    "for sent in thuc_sents_tokenized:\n",
    "    num_tokens_sents += len(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f2acfec5-7c54-443b-84ea-17179a9ee1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens_chapts = 0\n",
    "for sent in thuc_chaps_tokenized:\n",
    "    num_tokens_chapts += len(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "ddcae03a-a70f-4ff7-a1cb-fd25d5cca41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_chapts == num_tokens_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "f89459c5-4fe4-4210-b6ed-52f8be0feb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244871"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_chapts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "b75393d3-0423-41c4-9472-0640cae6adfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244871"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64be901a-732d-4db8-a9f8-b76c2fa8c701",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Find data errors in tokenized docs: difference in length of tokens = 20 initially"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cac9ab-c6e4-4795-a90d-03dedd33ced3",
   "metadata": {},
   "source": [
    "Data errors that I fixed in txt file (to which print out from xml is saved)\n",
    "- 29475 (book 1, chapter 136) \"égal;qu’enfin\" --> no whitespace after ;\n",
    "- book 2, chapter 13: 'Potidée;·', '—', 'dans' --> added whitespace after ;\n",
    "- ...\n",
    "\n",
    "All missing whitespaces after ; In one case it was after ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "c229dd9f-adf6-4b60-86d8-2189d6c2b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc_tokens_from_sents = flatten_list(thuc_sents_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "a479bda1-793a-4675-9728-8d6a978295f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244871"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thuc_tokens_from_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "386d19b6-9324-4674-ab74-88e3e693e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc_tokens_from_chapts = flatten_list(thuc_chaps_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "bdbc07a1-caa3-40e8-a57b-067e67c2587d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244871"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thuc_tokens_from_chapts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "b47c3f25-c05a-47b6-96f3-5f7e45df51ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['héros;»', 'eh']"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thuc_tokens_from_chapts[113628:113630]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "70d9f141-6b9b-4022-9c3c-878e87bd5ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['héros;»', 'eh']"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thuc_tokens_from_sents[113628:113630]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "9c5892a9-8f81-45e7-9ea1-698cf9667dde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, token in enumerate(thuc_tokens_from_chapts):\n",
    "    if token != thuc_tokens_from_sents[idx]:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed58e8b-e272-413c-a1a9-17c7165436bb",
   "metadata": {},
   "source": [
    "### build dict sent idx to section name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "fa4fe486-5eb8-42d1-bdb8-cfb6b1cc0503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### OLD VERSION - does not account for sents that pass chapter boundaries ####\n",
    "#### resulting dict for fr text is the same with this function and new function - sents don't cross chapters? ####\n",
    "\n",
    "def build_sent_to_section_dict(lst_tokenized_sents, lst_tokenized_chapts,\n",
    "                               dict_chapter_2_section):\n",
    "    \"\"\"\n",
    "    Build dict of sentence idx to section name\n",
    "    \"\"\"\n",
    "    sent_idx_2_section_name = {}\n",
    "    token_counter = 0 # per section/chapter\n",
    "    current_section_idx = 0\n",
    "    for idx_sent, sent in enumerate(lst_tokenized_sents):\n",
    "        token_counter += len(sent)\n",
    "        current_chapter_length = len(lst_tokenized_chapts[current_section_idx])\n",
    "        if token_counter <= current_chapter_length:\n",
    "            # add sent to dict\n",
    "            sent_idx_2_section_name[idx_sent] = dict_chapter_2_section[current_section_idx]\n",
    "        else:\n",
    "            # reset token counter and move on to next chapter/section\n",
    "            token_counter = len(sent)\n",
    "            current_section_idx += 1\n",
    "            # add sent to dict\n",
    "            sent_idx_2_section_name[idx_sent] = dict_chapter_2_section[current_section_idx]\n",
    "            \n",
    "    return sent_idx_2_section_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "2e860879-6163-439a-9de8-a5f74d126b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sent_to_section_dict_2(lst_tokenized_sents, lst_tokenized_chapts,\n",
    "                               dict_chapter_2_section):\n",
    "    \"\"\"\n",
    "    Build dict of sentence idx to section name\n",
    "    \"\"\"\n",
    "    sent_idx_2_section_name = {}\n",
    "    token_counter = 0 # per section/chapter\n",
    "    current_section_idx = 0\n",
    "    # have_match = False\n",
    "\n",
    "    for idx_sent, sent in enumerate(lst_tokenized_sents):\n",
    "        token_counter += len(sent)\n",
    "        current_chapter_length = len(lst_tokenized_chapts[current_section_idx])\n",
    "        \n",
    "        if token_counter < current_chapter_length:\n",
    "            # add sent to dict\n",
    "            sent_idx_2_section_name[idx_sent] = dict_chapter_2_section[current_section_idx]\n",
    "        elif token_counter == current_chapter_length:\n",
    "            # # change flag\n",
    "            # have_match = True\n",
    "            # add sent to dict as part of current section\n",
    "            sent_idx_2_section_name[idx_sent] = dict_chapter_2_section[current_section_idx]\n",
    "            # reset token counter and current section idx for next sent iteration\n",
    "            token_counter = 0\n",
    "            current_section_idx += 1\n",
    "        else: # token_counter > current_chapter_length, i.e. we've crossed a section boundary \n",
    "            # add sent to current section and next section\n",
    "            sent_idx_2_section_name[idx_sent] = [\n",
    "                dict_chapter_2_section[current_section_idx], \n",
    "                dict_chapter_2_section[current_section_idx+1]\n",
    "            ]\n",
    "            # adjust token counter by only including portion of sent in new section\n",
    "            token_counter = token_counter - current_chapter_length\n",
    "            # update current section idx for next sent iteration\n",
    "            current_section_idx += 1\n",
    "            \n",
    "#         else:\n",
    "#             if have_match == True:\n",
    "#                 # add sent to current section\n",
    "#                 sent_idx_2_section_name[idx_sent] = dict_chapter_2_section[current_section_idx]\n",
    "#                 # reset token counter fully\n",
    "#                 token_counter = len(sent)\n",
    "#                 print(\"+++++++++++++++++++++++++++++++++++\")\n",
    "#             else:\n",
    "#                 print(f\"sent idx is {idx_sent}\")\n",
    "#                 print(f\"token counter is {token_counter} and sent length is {len(sent)}\")\n",
    "#                 print(f\"current chapter length is {current_chapter_length}\")\n",
    "#                 print(f\"current section idx is {current_section_idx}\")\n",
    "#                 # add sent to current section and next section\n",
    "#                 sent_idx_2_section_name[idx_sent] = [\n",
    "#                     dict_chapter_2_section[current_section_idx], \n",
    "#                     dict_chapter_2_section[current_section_idx+1]\n",
    "#                 ]\n",
    "#                 # adjust token counter by including portion of sent in new section only\n",
    "#                 token_counter = token_counter - current_chapter_length\n",
    "#             # update current section idx for both cases\n",
    "#             current_section_idx += 1\n",
    "#             # reset have_match in case it was True at beginning of if statement\n",
    "#             have_match = False\n",
    "        \n",
    "    return sent_idx_2_section_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bed086-abb5-4fce-b5b0-1202cd850b86",
   "metadata": {
    "tags": []
   },
   "source": [
    "### get dict for fr sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "1f143577-9fcc-4d7f-8cd7-4f4f3943f67a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fr_sent_2_section_name_OLD = build_sent_to_section_dict(\n",
    "    thuc_sents_tokenized, thuc_chaps_tokenized, idx_thuc_fr_chap_sents_2_section_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9fcdbd32-a94c-4089-949e-d492659225f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fr_sent_2_section_name = build_sent_to_section_dict_2(\n",
    "    thuc_sents_tokenized, thuc_chaps_tokenized, idx_thuc_fr_chap_sents_2_section_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "437a8edb-74dd-4dbc-b4e6-7880a691f5c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_sent_2_section_name_OLD == fr_sent_2_section_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "055456a0-1db6-4383-b6fa-0faeaf3086b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fr_sent_2_section_name) == len(thuc_sents_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63da3160-a841-4dcd-80fe-b4daafbdd5b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get dict for greek sents, using thuc_grk_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "226826b3-1c7c-4634-9e61-8149d421e5b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(lst_text):\n",
    "    tokenized = []\n",
    "    for idx, sent in enumerate(lst_text):\n",
    "        tokenized.append(sent.split())\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a7750d-d003-4d66-ba04-da1b5a85e590",
   "metadata": {
    "tags": []
   },
   "source": [
    "### tokenize thuc_grk_processed (per sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "277832dc-dcad-403d-9aa9-79b793172747",
   "metadata": {},
   "outputs": [],
   "source": [
    "grk_sents_tokenized = tokenize(thuc_grk_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "c3b6d541-9966-4432-86ae-ea2bd127d092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thuc_grk_processed) == len(grk_sents_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "45e2af73-46c5-4d1e-a9f1-27287fae1928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6097"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thuc_grk_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b1ff48-d5b6-40c9-a203-9d256a035bc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get grk by chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "236f71a6-a8ef-482a-8910-6c0b394582a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>id</th>\n",
       "      <th>loc</th>\n",
       "      <th>seq</th>\n",
       "      <th>text</th>\n",
       "      <th>cites</th>\n",
       "      <th>group</th>\n",
       "      <th>lang</th>\n",
       "      <th>title</th>\n",
       "      <th>translation</th>\n",
       "      <th>wlang</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001:1.1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>Θουκυδίδης Ἀθηναῖος ξυνέγραψε τὸν πόλεμον τῶν\\...</td>\n",
       "      <td>[book, chapter, section]</td>\n",
       "      <td>Thucydides</td>\n",
       "      <td>grc</td>\n",
       "      <td>History of the Peloponnesian War</td>\n",
       "      <td>False</td>\n",
       "      <td>grc</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001:1.1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>κίνησις γὰρ αὕτη μεγίστη δὴ τοῖς Ἕλλησιν ἐγένε...</td>\n",
       "      <td>[book, chapter, section]</td>\n",
       "      <td>Thucydides</td>\n",
       "      <td>grc</td>\n",
       "      <td>History of the Peloponnesian War</td>\n",
       "      <td>False</td>\n",
       "      <td>grc</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001:1.1.3</td>\n",
       "      <td>2</td>\n",
       "      <td>τὰ γὰρ πρὸ αὐτῶν καὶ τὰ ἔτι παλαίτερα σαφῶς μὲ...</td>\n",
       "      <td>[book, chapter, section]</td>\n",
       "      <td>Thucydides</td>\n",
       "      <td>grc</td>\n",
       "      <td>History of the Peloponnesian War</td>\n",
       "      <td>False</td>\n",
       "      <td>grc</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001:1.2.1</td>\n",
       "      <td>3</td>\n",
       "      <td>φαίνεται γὰρ ἡ νῦν Ἑλλὰς καλουμένη οὐ πάλαι βε...</td>\n",
       "      <td>[book, chapter, section]</td>\n",
       "      <td>Thucydides</td>\n",
       "      <td>grc</td>\n",
       "      <td>History of the Peloponnesian War</td>\n",
       "      <td>False</td>\n",
       "      <td>grc</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001:1.2.2</td>\n",
       "      <td>4</td>\n",
       "      <td>τῆς γὰρ ἐμπορίας οὐκ οὔσης, οὐδ’ ἐπιμειγνύντες...</td>\n",
       "      <td>[book, chapter, section]</td>\n",
       "      <td>Thucydides</td>\n",
       "      <td>grc</td>\n",
       "      <td>History of the Peloponnesian War</td>\n",
       "      <td>False</td>\n",
       "      <td>grc</td>\n",
       "      <td>urn:cts:greekLit:tlg0003.tlg001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           book  \\\n",
       "0  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2   \n",
       "1  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2   \n",
       "2  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2   \n",
       "3  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2   \n",
       "4  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2   \n",
       "\n",
       "                                                  id  \\\n",
       "0  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...   \n",
       "1  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...   \n",
       "2  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...   \n",
       "3  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...   \n",
       "4  urn:cts:greekLit:tlg0003.tlg001.perseus-grc2:1...   \n",
       "\n",
       "                                     loc  seq  \\\n",
       "0  urn:cts:greekLit:tlg0003.tlg001:1.1.1    0   \n",
       "1  urn:cts:greekLit:tlg0003.tlg001:1.1.2    1   \n",
       "2  urn:cts:greekLit:tlg0003.tlg001:1.1.3    2   \n",
       "3  urn:cts:greekLit:tlg0003.tlg001:1.2.1    3   \n",
       "4  urn:cts:greekLit:tlg0003.tlg001:1.2.2    4   \n",
       "\n",
       "                                                text  \\\n",
       "0  Θουκυδίδης Ἀθηναῖος ξυνέγραψε τὸν πόλεμον τῶν\\...   \n",
       "1  κίνησις γὰρ αὕτη μεγίστη δὴ τοῖς Ἕλλησιν ἐγένε...   \n",
       "2  τὰ γὰρ πρὸ αὐτῶν καὶ τὰ ἔτι παλαίτερα σαφῶς μὲ...   \n",
       "3  φαίνεται γὰρ ἡ νῦν Ἑλλὰς καλουμένη οὐ πάλαι βε...   \n",
       "4  τῆς γὰρ ἐμπορίας οὐκ οὔσης, οὐδ’ ἐπιμειγνύντες...   \n",
       "\n",
       "                      cites       group lang  \\\n",
       "0  [book, chapter, section]  Thucydides  grc   \n",
       "1  [book, chapter, section]  Thucydides  grc   \n",
       "2  [book, chapter, section]  Thucydides  grc   \n",
       "3  [book, chapter, section]  Thucydides  grc   \n",
       "4  [book, chapter, section]  Thucydides  grc   \n",
       "\n",
       "                              title  translation wlang  \\\n",
       "0  History of the Peloponnesian War        False   grc   \n",
       "1  History of the Peloponnesian War        False   grc   \n",
       "2  History of the Peloponnesian War        False   grc   \n",
       "3  History of the Peloponnesian War        False   grc   \n",
       "4  History of the Peloponnesian War        False   grc   \n",
       "\n",
       "                              work  \n",
       "0  urn:cts:greekLit:tlg0003.tlg001  \n",
       "1  urn:cts:greekLit:tlg0003.tlg001  \n",
       "2  urn:cts:greekLit:tlg0003.tlg001  \n",
       "3  urn:cts:greekLit:tlg0003.tlg001  \n",
       "4  urn:cts:greekLit:tlg0003.tlg001  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thuc_grc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "2f7f2d6e-b769-4695-a678-31a209fc58f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 146, 2: 103, 3: 116, 4: 135, 5: 116, 6: 105, 7: 87, 8: 109}"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_nums = [x for x in range(1, 9)]\n",
    "chap_nums = [146, 103, 116, 135, 116, 105, 87, 109]\n",
    "book_to_number_chaps = dict(zip(book_nums, chap_nums))\n",
    "book_to_number_chaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "01e1a3c1-5e1a-497f-aed2-10b2dbc528ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_to_number_chaps[1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "1f376e69-5cd3-4c0e-b013-5de1e99f009b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grk_txt_by_chapter = []\n",
    "grk_chap_idx_2_chap_name = {}\n",
    "idx_counter = 0\n",
    "\n",
    "for book_idx in range(1, 9):\n",
    "    number_chapters = book_to_number_chaps[book_idx] + 1\n",
    "    book_txt_by_chapter = []\n",
    "    for chapter_num in range(1, number_chapters):\n",
    "        loc_tag = \"urn:cts:greekLit:tlg0003.tlg001:\" + str(book_idx) + \".\" + str(chapter_num) + \".\"\n",
    "        chapter_text = concatenate_txt(thuc_grc_df[thuc_grc_df['loc'].str.startswith(loc_tag)]['text'].replace('\\n',' ', regex=True))\n",
    "        book_txt_by_chapter.append(chapter_text)\n",
    "        # add to dict. chap name format: \"booknum,chapnum\"\n",
    "        chapter_name = str(book_idx) + \",\" + str(chapter_num)\n",
    "        grk_chap_idx_2_chap_name[idx_counter] = chapter_name\n",
    "        idx_counter += 1\n",
    "    # add chapters to full text list\n",
    "    grk_txt_by_chapter.extend(book_txt_by_chapter)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "8d497756-b37c-438e-b06d-f9c75fc0713e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grk_txt_by_chapter) == sum(chap_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "50756e9e-0d71-45ad-857a-44696f659d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ὁ δὲ Τισσαφέρνης αἰσθόμενος καὶ τοῦτο τῶν Πελοποννησίων τὸ ἔργον καὶ οὐ μόνον τὸ ἐν τῇ Μιλήτῳ καὶ Κνίδῳ ʽκαὶ ἐνταῦθα γὰρ αὐτοῦ ἐξεπεπτώκεσαν οἱ φρουροἴ, διαβεβλῆσθαί τε νομίσας αὐτοῖς σφόδρα καὶ δείσας μὴ καὶ ἄλλο τι ἔτι βλάπτωσι, καὶ ἅμα ἀχθόμενος εἰ Φαρνάβαζος ἐξ ἐλάσσονος χρόνου καὶ δαπάνης δεξάμενος αὐτοὺς κατορθώσει τι μᾶλλον τῶν πρὸς τοὺς Ἀθηναίους, πορεύεσθαι διενοεῖτο πρὸς αὐτοὺς ἐπὶ τοῦ Ἑλλησπόντου, ὅπως μέμψηταί τε τῶν περὶ τὴν Ἄντανδρον γεγενημένων καὶ τὰς διαβολὰς καὶ περὶ τῶν Φοινισσῶν νεῶν καὶ τῶν ἄλλων ὡς εὐπρεπέστατα ἀπολογήσηται. καὶ ἀφικόμενος πρῶτον ἐς Ἔφεσον θυσίαν ἐποιήσατο τῇ Ἀρτέμιδι.  [ὅταν ὁ μετὰ τοῦτο τὸ θέρος χειμὼν τελευτήσῃ, ἓν καὶ εἰκοστὸν ἔτος πληροῦται.] '"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grk_txt_by_chapter[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "7d92355a-3c35-4a23-899c-8644da1a0991",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "917"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grk_chap_idx_2_chap_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "e2dcb96f-744d-48f2-a8ac-b24f0576be77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grk_chap_idx_2_chap_name) == len(grk_txt_by_chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d1ad3-2ab8-4cc3-a910-12d958161c21",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TODO: not necessary anymore? send grk txt by chapter to file, to edit whitespace errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "44bd15b7-4705-4be8-8701-4e8327118882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grk_txt_to_edit_path = \"/home/craig.car/spring2023/data/align_noisy_data/thucydides/grk_text_by_chapter.txt\"\n",
    "# write_file(grk_txt_by_chapter, grk_txt_to_edit_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ea4022-5775-4af5-8945-ad516a151a74",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tokenize grk text by chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "087ba74a-cefb-4bc3-a6e1-c1a0ae365bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: not necessary anymore?\n",
    "# # load grk text by chapter from file, where whitespace errors have been corrected\n",
    "# grk_txt_by_chapter_cleaned = load_txt_as_lst(grk_txt_to_edit_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "0d8beef5-8ccd-4109-88c1-d8f89f1a55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent_idx, sent in enumerate(grk_txt_by_chapter):\n",
    "    grk_txt_by_chapter[sent_idx] = grk_txt_by_chapter[sent_idx].replace(\".\", \". \")\n",
    "    grk_txt_by_chapter[sent_idx] = grk_txt_by_chapter[sent_idx].replace(\":\", \": \")\n",
    "    grk_txt_by_chapter[sent_idx] = grk_txt_by_chapter[sent_idx].replace(\";\", \"; \")\n",
    "\n",
    "for sent_idx, sent in enumerate(grk_txt_by_chapter):\n",
    "    grk_txt_by_chapter[sent_idx] = grk_txt_by_chapter[sent_idx].replace(\". ’\", \".’\")\n",
    "    grk_txt_by_chapter[sent_idx] = grk_txt_by_chapter[sent_idx].replace(\": ’\", \":’\")\n",
    "    grk_txt_by_chapter[sent_idx] = grk_txt_by_chapter[sent_idx].replace(\". ]\", \".]\")\n",
    "    grk_txt_by_chapter[sent_idx] = grk_txt_by_chapter[sent_idx].replace(\"\\n\", \" \")\n",
    "    # grk_txt_by_chapter_cleaned[sent_idx] = re.sub(\". ’\", \".’\", grk_txt_by_chapter_cleaned[sent_idx])\n",
    "    # grk_txt_by_chapter_cleaned[sent_idx] = re.sub(\"\\n\", \" \", grk_txt_by_chapter_cleaned[sent_idx])\n",
    "    # grk_txt_by_chapter_cleaned[sent_idx] = re.sub(\". ]\", \".]\", grk_txt_by_chapter_cleaned[sent_idx])\n",
    "\n",
    "for sent_idx, sent in enumerate(grk_txt_by_chapter):    \n",
    "    grk_txt_by_chapter[sent_idx] = grk_txt_by_chapter[sent_idx].replace(\" . . .\", \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "a3b5e26e-26fa-4661-abe0-ba537a91617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.sub(\". ’\", \".’\", grk_txt_by_chapter_cleaned[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "14aae2c4-c532-4ddf-9fdf-a75465df9d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grk_txt_by_chapter[482]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "df38e72d-2aac-484f-b19d-a30fcd62f735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grk_chaps_tokenized = tokenize(grk_txt_by_chapter_cleaned)\n",
    "grk_chaps_tokenized = tokenize(grk_txt_by_chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "2f5def90-3fa8-41fd-af21-6e9fbe91dc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grk_chaps_tokenized) == len(grk_txt_by_chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895524ac-5635-46e4-9c5e-61587110e6bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Find data errors in tokenized docs for Grk: difference in length = 104"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba656cf9-117c-4e13-88b7-8bb146f5f6db",
   "metadata": {},
   "source": [
    "All were due to missing whitespace after punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "95167d50-979d-4ac0-8a32-669fa0253934",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150155"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_sents = 0\n",
    "for sent in grk_sents_tokenized:\n",
    "    num_tokens_sents += len(sent)\n",
    "num_tokens_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "9f79d05c-d438-4a9e-bb38-54ece11b634a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150155"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_chaps = 0\n",
    "for sent in grk_chaps_tokenized:\n",
    "    num_tokens_chaps += len(sent)\n",
    "num_tokens_chaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "2b4d3370-1c13-4849-a481-c0dc15204875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150155"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grk_tokens_from_sents = flatten_list(grk_sents_tokenized)\n",
    "len(grk_tokens_from_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "7eade78c-b30d-47ec-9044-0541d6596c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150155"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grk_tokens_from_chaps = flatten_list(grk_chaps_tokenized)\n",
    "len(grk_tokens_from_chaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "5159176f-4ee8-4fc8-a643-1454b666b429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['πληροῦται.]']"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grk_tokens_from_chaps[150154:150156]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "5769fa87-1cb8-4d01-9b7e-416eccfccce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['πληροῦται.]']"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grk_tokens_from_sents[150154:150156]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "6e184fcf-9088-46f2-9cc8-b5249b4a5911",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, token in enumerate(grk_tokens_from_chaps):\n",
    "    if token != grk_tokens_from_sents[idx]:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469f004-4f2c-447d-9882-e558aab202cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### get dict for grk sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "a9f05977-0609-4682-b76e-0329c91f80f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Original code to fix bugs in building grk dict. Moved to function, build_sent_to_section_dict_2() #####\n",
    "\n",
    "# grk_sent_2_section_name = {}\n",
    "# token_counter = 0 # per section/chapter\n",
    "# current_section_idx = 0\n",
    "# have_match = False\n",
    "\n",
    "# for idx_sent, sent in enumerate(grk_sents_tokenized):\n",
    "#     token_counter += len(sent)\n",
    "#     current_chapter_length = len(grk_chaps_tokenized[current_section_idx])\n",
    "#     if token_counter < current_chapter_length:\n",
    "#         # add sent to dict\n",
    "#         grk_sent_2_section_name[idx_sent] = grk_chap_idx_2_chap_name[current_section_idx]\n",
    "#     elif token_counter == current_chapter_length:\n",
    "#         grk_sent_2_section_name[idx_sent] = grk_chap_idx_2_chap_name[current_section_idx]\n",
    "#         # print(\"+++++++\")\n",
    "#         # print(f\"token_counter == current chap length. sent idx is {idx_sent}\")\n",
    "#         # print(f\"current section idx is {current_section_idx}\")\n",
    "#         have_match = True\n",
    "#     else:\n",
    "#         # print(\"======\")\n",
    "#         # print(f\"moved to new section. sent idx is {idx_sent}\")\n",
    "#         # print(f\"section idx was {current_section_idx}\")\n",
    "#         # print(f\"token counter was {token_counter} and chap length was {current_chapter_length}\")\n",
    "        \n",
    "#         if have_match == True:\n",
    "#             # add sent to next section only\n",
    "#             grk_sent_2_section_name[idx_sent] = grk_chap_idx_2_chap_name[current_section_idx+1]\n",
    "#             # reset token counter fully\n",
    "#             token_counter = len(sent)\n",
    "            \n",
    "#         else:\n",
    "#             # add sent to current section and next section\n",
    "#             grk_sent_2_section_name[idx_sent] = [\n",
    "#                 grk_chap_idx_2_chap_name[current_section_idx], \n",
    "#                 grk_chap_idx_2_chap_name[current_section_idx+1]\n",
    "#             ]\n",
    "#             # adjust token counter by including portion of sent in new section only\n",
    "#             token_counter = token_counter - current_chapter_length\n",
    "            \n",
    "#         # update current section idx for both cases\n",
    "#         current_section_idx += 1\n",
    "#         # reset have_match in case it was True at beginning of if statement\n",
    "#         have_match = False\n",
    "        \n",
    "#         # current_chapter_length = len(grk_chaps_tokenized[current_section_idx])\n",
    "        \n",
    "#     # print(f\"current sent_idx is {idx_sent}\")\n",
    "#     # print(f\"sent length is {len(sent)}\")\n",
    "#     # print(f\"token counter is {token_counter}\")\n",
    "#     # print(f\"section length is {current_chapter_length}\")\n",
    "#     # print(grk_sent_2_section_name[idx_sent])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "417d9f97-c4eb-4bb3-86e7-369e93ea55e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grk_sent_2_section_name = build_sent_to_section_dict_2(\n",
    "    grk_sents_tokenized, grk_chaps_tokenized, grk_chap_idx_2_chap_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "8f5ce2c9-9b40-4ba0-9d30-8c66b88ed80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'τοιαῦτα μὲν οἱ Κερκυραῖοι εἶπον:'"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thuc_grk_processed[229]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "5a18aa1a-6190-44a9-9a62-b61cb51d27b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,36'"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grk_sent_2_section_name[229]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "daa93c7d-ae4a-44d7-b746-c976d0468577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‘καὶ ὅτῳ τάδε ξυμφέροντα μὲν δοκεῖ λέγεσθαι, φοβεῖται δὲ μὴ δι’ αὐτὰ πειθόμενος τὰς σπονδὰς λύσῃ, γνώτω τὸ μὲν δεδιὸς αὐτοῦ ἰσχὺν ἔχον τοὺς ἐναντίους μᾶλλον φοβῆσον, τὸ δὲ θαρσοῦν μὴ δεξαμένου ἀσθενὲς ὂν πρὸς ἰσχύοντας τοὺς ἐχθροὺς ἀδεέστερον ἐσόμενον, καὶ ἅμα οὐ περὶ τῆς Κερκύρας νῦν τὸ πλέον ἢ καὶ τῶν Ἀθηνῶν βουλευόμενος, καὶ οὐ τὰ κράτιστα αὐταῖς προνοῶν, ὅταν ἐς τὸν μέλλοντα καὶ ὅσον οὐ παρόντα πόλεμον τὸ αὐτίκα περισκοπῶν ἐνδοιάζῃ χωρίον προσλαβεῖν ὃ μετὰ μεγίστων καιρῶν οἰκειοῦταί τε καὶ πολεμοῦται.   τῆς τε γὰρ Ἰταλίας καὶ Σικελίας καλῶς παράπλου κεῖται, ὥστε μήτε ἐκεῖθεν ναυτικὸν ἐᾶσαι Πελοποννησίοις ἐπελθεῖν τό τε ἐνθένδε πρὸς τἀκεῖ παραπέμψαι, καὶ ἐς τἆλλα ξυμφορώτατόν ἐστιν.   βραχυτάτῳ δ’ ἂν κεφαλαίῳ, τοῖς τε ξύμπασι καὶ καθ’ ἕκαστον, τῷδ’ ἂν μὴ προέσθαι ἡμᾶς μάθοιτε:  τρία μὲν ὄντα λόγου ἄξια τοῖς Ἕλλησι ναυτικά, τὸ παρ’ ὑμῖν καὶ τὸ ἡμέτερον καὶ τὸ Κορινθίων:  τούτων δὲ εἰ περιόψεσθε τὰ δύο ἐς ταὐτὸν ἐλθεῖν καὶ Κορίνθιοι ἡμᾶς προκαταλήψονται, Κερκυραίοις τε καὶ Πελοποννησίοις ἅμα ναυμαχήσετε, δεξάμενοι δὲ ἡμᾶς ἕξετε πρὸς αὐτοὺς πλείοσι ναυσὶ ταῖς ἡμετέραις ἀγωνίζεσθαι.’  τοιαῦτα μὲν οἱ Κερκυραῖοι εἶπον:  οἱ δὲ Κορίνθιοι μετ’ αὐτοὺς τοιάδε.  '"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grk_txt_by_chapter[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "2cc6f86b-8944-41e1-8474-ead89e16d5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,36'"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grk_chap_idx_2_chap_name[35]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ec733-53cd-433f-ace3-d81287e5cd27",
   "metadata": {
    "tags": []
   },
   "source": [
    "### write sent to section name dicts to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "40fed079-781c-414b-a207-b0ca43d0eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_out = \"/home/craig.car/spring2023/data/align_noisy_data/thucydides/grk_sent_2_section_name_dict.json\"\n",
    "# with open(path_out, 'w') as fp:\n",
    "#     json.dump(grk_sent_2_section_name, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "ca33422f-08c0-49bb-8fd5-9f1a43c415d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_out = \"/home/craig.car/spring2023/data/align_noisy_data/thucydides/fr_sent_2_section_name_dict.json\"\n",
    "# with open(path_out, 'w') as fp:\n",
    "#     json.dump(fr_sent_2_section_name, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1c7878-bfd8-48a4-9224-f50832a8e8ef",
   "metadata": {},
   "source": [
    "### get grk sents that cross chapter boundaries\n",
    "Sentences here: https://docs.google.com/spreadsheets/d/1cQJ9Ypt_h4cHS-0ABbKfDHAE57ZLU32IONAadqdifaU/edit#gid=1836213835"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "3f102eaf-7cf8-4c3c-99b5-98c34af5e040",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "values = list(grk_sent_2_section_name.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "4aa7862d-cfab-4c8c-a91c-bd45ebc4314e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ἀγανακτῶν δὲ ὁ μὲν Τισσαφέρνης ἀπεχώρησεν ἀπ’ αὐτῶν δι’  ὀργῆς καὶ ἄπρακτος, οἱ δ’ ἐς τὴν Ῥόδον ἐπικηρυκευομένων ἀπὸ τῶν δυνατωτάτων ἀνδρῶν τὴν γνώμην εἶχον πλεῖν, ἐλπίζοντες νῆσόν τε οὐκ ἀδύνατον καὶ ναυβατῶν πλήθει καὶ πεζῷ προσάξεσθαι, καὶ ἅμα ἡγούμενοι αὐτοὶ ἀπὸ τῆς ὑπαρχούσης ξυμμαχίας δυνατοὶ ἔσεσθαι Τισσαφέρνην μὴ αἰτοῦντες χρήματα τρέφειν τὰς ναῦς.\n",
      "['8,43', '8,44']\n",
      "οἱ δὲ Ἀθηναῖοι ταῖς ἐκ τῆς Σάμου ναυσὶ πάσαις, ὡς ᾔσθοντο τὰ τῆς ναυμαχίας, πλεύσαντες ἐς τὴν Σύμην καὶ ἐπὶ μὲν τὸ ἐν τῇ Κνίδῳ ναυτικὸν οὐχ ὁρμήσαντες, οὐδ᾽ ἐκεῖνοι ἐπ’ ἐκείνους, λαβόντες δὲ τὰ ἐν τῇ Σύμῃ σκεύη τῶν νεῶν καὶ Λωρύμοις τοῖς ἐν τῇ ἠπείρῳ προσβαλόντες ἀπέπλευσαν ἐς τὴν Σάμον.   ἅπασαι δ’ ἤδη οὖσαι ἅμα ἐν τῇ Κνίδῳ αἱ τῶν Πελοποννησίων νῆες ἐπεσκευάζοντό τε εἴ τι ἔδει καὶ πρὸς τὸν Τισσαφέρνην (παρεγένετο γάρ) λόγους ἐποιοῦντο οἱ ἕνδεκα ἄνδρες τῶν Λακεδαιμονίων περί τε τῶν ἤδη πεπραγμένων, εἴ τι μὴ ἤρεσκεν αὐτοῖς, καὶ περὶ τοῦ μέλλοντος πολέμου, ὅτῳ τρόπῳ ἄριστα καὶ ξυμφορώτατα ἀμφοτέροις πολεμήσεται.   μάλιστα δὲ ὁ Λίχας ἐσκόπει τὰ ποιούμενα, καὶ τὰς σπονδὰς οὐδετέρας, οὔτε τὰς Χαλκιδέως οὔτε τὰς Θηριμένους, ἔφη καλῶς ξυγκεῖσθαι, ἀλλὰ δεινὸν εἶναι εἰ χώρας ὅσης βασιλεὺς καὶ οἱ πρόγονοι ἦρξαν πρότερον, ταύτης καὶ νῦν ἀξιώσει κρατεῖν:  ἐνεῖναι γὰρ καὶ νήσους ἁπάσας πάλιν δουλεύειν καὶ Θεσσαλίαν καὶ Λοκροὺς καὶ τὰ μέχρι Βοιωτῶν, καὶ ἀντ’ ἐλευθερίας ἂν Μηδικὴν ἀρχὴν τοῖς Ἕλλησι τοὺς Λακεδαιμονίους περιθεῖναι.   ἑτέρας οὖν ἐκέλευε βελτίους σπένδεσθαι, ἢ ταύταις γε οὐ χρήσεσθαι, οὐδὲ τῆς τροφῆς ἐπὶ τούτοις δεῖσθαι οὐδέν.  ἀγανακτῶν δὲ ὁ μὲν Τισσαφέρνης ἀπεχώρησεν ἀπ’ αὐτῶν δι’  ὀργῆς καὶ ἄπρακτος, \n",
      "οἱ δ’ ἐς τὴν Ῥόδον ἐπικηρυκευομένων ἀπὸ τῶν δυνατωτάτων ἀνδρῶν τὴν γνώμην εἶχον πλεῖν, ἐλπίζοντες νῆσόν τε οὐκ ἀδύνατον καὶ ναυβατῶν πλήθει καὶ πεζῷ προσάξεσθαι, καὶ ἅμα ἡγούμενοι αὐτοὶ ἀπὸ τῆς ὑπαρχούσης ξυμμαχίας δυνατοὶ ἔσεσθαι Τισσαφέρνην μὴ αἰτοῦντες χρήματα τρέφειν τὰς ναῦς.   πλεύσαντες οὖν εὐθὺς ἐν τῷ αὐτῷ χειμῶνι ἐκ τῆς Κνίδου καὶ προσβαλόντες Καμείρῳ τῆς Ῥοδίας πρῶτον ναυσὶ τέσσαρσι καὶ ἐνενήκοντα ἐξεφόβησαν μὲν τοὺς πολλοὺς οὐκ εἰδότας τὰ πρασσόμενα, καὶ ἔφευγον, ἄλλως τε καὶ ἀτειχίστου οὔσης τῆς πόλεως:  εἶτα ξυγκαλέσαντες οἱ Λακεδαιμόνιοι τούτους τε καὶ τοὺς ἐκ τοῖν δυοῖν πολέοιν, Λίνδου καὶ Ἰηλυσοῦ, Ῥοδίους ἔπεισαν ἀποστῆναι Ἀθηναίων:  καὶ προσεχώρησε Ῥόδος Πελοποννησίοις.   οἱ δὲ Ἀθηναῖοι κατὰ τὸν καιρὸν τοῦτον ταῖς ἐκ τῆς Σάμου ναυσὶν αἰσθόμενοι ἔπλευσαν μὲν βουλόμενοι φθάσαι καὶ ἐπεφάνησαν πελάγιοι, ὑστερήσαντες δὲ οὐ πολλῷ τὸ μὲν παραχρῆμα ἀπέπλευσαν ἐς Χάλκην, ἐντεῦθεν δ’ ἐς Σάμον, ὕστερον δὲ ἐκ τῆς Χάλκης καὶ ἐκ τῆς Κῶ [καὶ ἐκ τῆς Σάμου] τοὺς ἐπίπλους ποιούμενοι ἐπὶ τὴν Ῥόδον ἐπολέμουν.   οἱ δὲ χρήματα μὲν ἐξέλεξαν ἐς δύο καὶ τριάκοντα τάλαντα οἱ Πελοποννήσιοι παρὰ τῶν Ῥοδίων, τὰ δ’ ἄλλα ἡσύχαζον ἡμέρας ὀγδοήκοντα, ἀνελκύσαντες τὰς ναῦς.  \n"
     ]
    }
   ],
   "source": [
    "num = 5677\n",
    "for lst in [thuc_grk_processed, grk_sent_2_section_name]:\n",
    "    print(lst[num])\n",
    "\n",
    "# get chap idx by searching for sent in grk_txt_by_chapter.txt\n",
    "chap = 850\n",
    "print(grk_txt_by_chapter[chap])\n",
    "print(grk_txt_by_chapter[chap+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "8f2e1f04-8c2a-4261-b9dc-18ae2309ec62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      "162\n",
      "2257\n",
      "3577\n",
      "5677\n"
     ]
    }
   ],
   "source": [
    "# idx of Grk sents that cross chapter boundaries (verified)\n",
    "for idx, value in enumerate(values):\n",
    "    if isinstance(value,list):\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef3652-bffd-4ca0-9629-ec8e5ca9892a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_alignments(fin):\n",
    "    \"\"\"\n",
    "    function built by vecalign. see:\n",
    "    https://github.com/caro28/vecalign/blob/master/dp_utils.py\n",
    "    \"\"\"\n",
    "    \n",
    "    alignments = []\n",
    "    with open(fin, 'rt', encoding=\"utf-8\") as infile:\n",
    "        for line in infile:\n",
    "            fields = [x.strip() for x in line.split(':') if len(x.strip())]\n",
    "            if len(fields) < 2:\n",
    "                raise Exception('Got line \"%s\", which does not have at least two \":\" separated fields' % line.strip())\n",
    "            try:\n",
    "                src = literal_eval(fields[0])\n",
    "                tgt = literal_eval(fields[1])\n",
    "            except:\n",
    "                raise Exception('Failed to parse line \"%s\"' % line.strip())\n",
    "            alignments.append((src, tgt))\n",
    "\n",
    "    # I know bluealign files have a few entries entries missing,\n",
    "    #   but I don't fix them in order to be consistent previous reported scores\n",
    "    return alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2350cc-2d3f-4b81-b640-32feeefcb24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vecalign results\n",
    "vec_rslts_path = \"/home/craig.car/spring2023/data/align_noisy_data/thucydides/el2fr_rslts_0418.txt\"\n",
    "el_2_fr_vec_rslts = read_alignments(vec_rslts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9af596-fd41-4e66-a213-fd3ee2f043d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "el_2_fr_vec_rslts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca67ccc-aa95-40bb-ba8e-31d91b7fda0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(grk_sent_2_section_name[5449])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9279c9cb-f101-499c-92b0-d8dbb1f29b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_sent_2_section_name[13809]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca528c-8223-4a51-b149-cb3b05881983",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fr_sent_2_section_name[el_2_fr_vec_rslts[0][1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb0a9c2-dec0-49cf-8601-bfc697c1e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c599fc-0a1a-4298-afc3-a9b3e25c2ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fr_section_names = np.unique(np.array(list(fr_sent_2_section_name.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1e9e19-c01e-4c3c-8f97-1e105ad1f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_extraneous_sections = ['book 1 introduction', 'book 1 notes', 'book 2 introduction',\n",
    "       'book 2 notes', 'book 3 introduction', 'book 3 notes',\n",
    "       'book 4 introduction', 'book 4 notes', 'book 5 introduction',\n",
    "       'book 5 notes', 'book 6 introduction', 'book 6 notes',\n",
    "       'book 7 introduction', 'book 7 notes', 'book 8 introduction',\n",
    "       'book 8 notes', 'foreword', 'index']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5440c2ef-f908-45e9-a235-cea2d2c095e9",
   "metadata": {},
   "source": [
    "## TODO: check rslts are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e34217-13dd-469b-a18c-5f60258ea627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tp_strict = 0 # +1 per alignment if there's an exact match\n",
    "tp_lax = 0 # +1 per alignment if there's any overlap\n",
    "overlaps = []\n",
    "errors = []\n",
    "fr_extraneous_sections = ['book 1 introduction', 'book 1 notes', 'book 2 introduction',\n",
    "       'book 2 notes', 'book 3 introduction', 'book 3 notes',\n",
    "       'book 4 introduction', 'book 4 notes', 'book 5 introduction',\n",
    "       'book 5 notes', 'book 6 introduction', 'book 6 notes',\n",
    "       'book 7 introduction', 'book 7 notes', 'book 8 introduction',\n",
    "       'book 8 notes', 'foreword', 'index']\n",
    "correct_nulls = 0\n",
    "\n",
    "for idx_align, alignment in enumerate(el_2_fr_vec_rslts):\n",
    "    src_sents = alignment[0]\n",
    "    tgt_sents = alignment[1]\n",
    "    # get set of chapters from src, then from tgt\n",
    "    chapters_from_src = set()\n",
    "    chapters_from_tgt = set()\n",
    "    # if alignment is null on src side, then chapters_from_src remains empty set\n",
    "    if src_sents != []:\n",
    "        for src_id in src_sents:\n",
    "            if isinstance(grk_sent_2_section_name[src_id], list):\n",
    "                for section_name in grk_sent_2_section_name[src_id]:\n",
    "                    chapters_from_src.add(section_name)\n",
    "            else:\n",
    "                chapters_from_src.add(grk_sent_2_section_name[src_id])\n",
    "    # if alignment is null on tgt side, then chapters_from_tgt remains empty set\n",
    "    if tgt_sents != []:\n",
    "        for tgt_id in tgt_sents:\n",
    "            if isinstance(fr_sent_2_section_name[tgt_id], list):\n",
    "                for section_name_ in fr_sent_2_section_name[tgt_id]:\n",
    "                    chapters_from_tgt.add(section_name_)\n",
    "            else:\n",
    "                chapters_from_tgt.add(fr_sent_2_section_name[tgt_id])\n",
    "                \n",
    "    # compare the sets, get tp strict and lax\n",
    "    if chapters_from_src == chapters_from_tgt:\n",
    "        tp_strict += 1\n",
    "        print(\"have exact match\")\n",
    "    \n",
    "    # account for correct null : fr extraneous sections \n",
    "    elif chapters_from_src == set():\n",
    "        tgt_counter = 0\n",
    "        for chapter in chapters_from_tgt:\n",
    "            if chapter in fr_extraneous_sections:\n",
    "                tgt_counter += 1\n",
    "        # tp_strict if all tgt chapters are extraneous\n",
    "        if tgt_counter == len(chapters_from_tgt):\n",
    "            tp_strict += 1\n",
    "            correct_nulls += 1\n",
    "            print(\"have correct null\")\n",
    "        \n",
    "    else:\n",
    "        overlap = chapters_from_src.intersection(chapters_from_tgt)\n",
    "        if len(overlap) != 0:\n",
    "            tp_lax += 1\n",
    "            overlaps.append(alignment)\n",
    "        else:\n",
    "            # save errors\n",
    "            error_dict = {}\n",
    "            error_dict[\"alignment\"] = alignment\n",
    "            error_dict[\"alignmnent_idx\"] = idx_align\n",
    "            error_dict[\"src_chapters\"] = chapters_from_src\n",
    "            error_dict[\"tgt_chapters\"] = chapters_from_tgt\n",
    "            errors.append(error_dict)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb1b073-485f-425e-be48-0c6e24a23f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_vec_rslts_chapter_level(vr_rslts_lst, el_sent2section_dict,\n",
    "                                 fr_sent2section_dict, fr_extra_section_names):\n",
    "\n",
    "    tp_strict = 0 # +1 per alignment if there's an exact match\n",
    "    tp_lax = 0 # +1 per alignment if there's any overlap\n",
    "    overlaps = []\n",
    "    errors = []\n",
    "    correct_nulls = 0\n",
    "\n",
    "    for idx_align, alignment in enumerate(vr_rslts_lst):\n",
    "        # skip alignments null on both sides\n",
    "        if alignment == ([],[]):\n",
    "            continue\n",
    "        else:\n",
    "            src_sents = alignment[0]\n",
    "            tgt_sents = alignment[1]\n",
    "            # get set of chapters from src, then from tgt\n",
    "            chapters_from_src = set()\n",
    "            chapters_from_tgt = set()\n",
    "            # if alignment is null on src side, then chapters_from_src remains empty set\n",
    "            if src_sents != []:\n",
    "                for src_id in src_sents:\n",
    "                    if isinstance(el_sent2section_dict[src_id], list):\n",
    "                        for section_name in el_sent2section_dict[src_id]:\n",
    "                            chapters_from_src.add(section_name)\n",
    "                    else:\n",
    "                        chapters_from_src.add(el_sent2section_dict[src_id])\n",
    "            # if alignment is null on tgt side, then chapters_from_tgt remains empty set\n",
    "            if tgt_sents != []:\n",
    "                for tgt_id in tgt_sents:\n",
    "                    if isinstance(fr_sent2section_dict[tgt_id], list):\n",
    "                        for section_name_ in fr_sent2section_dict[tgt_id]:\n",
    "                            chapters_from_tgt.add(section_name_)\n",
    "                    else:\n",
    "                        chapters_from_tgt.add(fr_sent2section_dict[tgt_id])\n",
    "\n",
    "            # compare the sets, get tp strict and lax\n",
    "            if chapters_from_src == chapters_from_tgt:\n",
    "                tp_strict += 1\n",
    "                print(\"have exact match\")\n",
    "\n",
    "            # account for correct null : afr extraneous sections \n",
    "            elif chapters_from_src == set():\n",
    "                tgt_counter = 0\n",
    "                for chapter in chapters_from_tgt:\n",
    "                    if chapter in fr_extra_section_names:\n",
    "                        tgt_counter += 1\n",
    "                # tp_strict if all tgt chapters are extraneous\n",
    "                if tgt_counter == len(chapters_from_tgt):\n",
    "                    tp_strict += 1\n",
    "                    correct_nulls += 1\n",
    "                    print(\"have correct null\")\n",
    "\n",
    "            else:\n",
    "                overlap = chapters_from_src.intersection(chapters_from_tgt)\n",
    "                if len(overlap) != 0:\n",
    "                    tp_lax += 1\n",
    "                    overlaps.append(alignment)\n",
    "                else:\n",
    "                    # save errors\n",
    "                    error_dict = {}\n",
    "                    error_dict[\"alignment\"] = alignment\n",
    "                    error_dict[\"alignmnent_idx\"] = idx_align\n",
    "                    error_dict[\"src_chapters\"] = chapters_from_src\n",
    "                    error_dict[\"tgt_chapters\"] = chapters_from_tgt\n",
    "                    errors.append(error_dict)\n",
    "        \n",
    "    return tp_strict, tp_lax, overlaps, errors, correct_nulls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0e7b0-75a4-4cbd-b3e9-b22e904719a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_rslts = [\n",
    "            ([], [13809]),\n",
    "            ([2], [154]),\n",
    "            ([954], [1833, 1846, 1880]),\n",
    "            ([2861], [11486]),\n",
    "            ([4201], [14187]),\n",
    "            ([6094], [16125]),\n",
    "            ([], [])\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af1927-b56a-40e2-a2f7-37f2136d4e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fr_extraneous_sections = ['book 1 introduction', 'book 1 notes', 'book 2 introduction',\n",
    "           'book 2 notes', 'book 3 introduction', 'book 3 notes',\n",
    "           'book 4 introduction', 'book 4 notes', 'book 5 introduction',\n",
    "           'book 5 notes', 'book 6 introduction', 'book 6 notes',\n",
    "           'book 7 introduction', 'book 7 notes', 'book 8 introduction',\n",
    "           'book 8 notes', 'foreword', 'index']\n",
    "\n",
    "tp_strict_, tp_lax_, overlaps_, errors_, correct_nulls_ = score_vec_rslts_chapter_level(\n",
    "    el_2_fr_vec_rslts, grk_sent_2_section_name, fr_sent_2_section_name, fr_extraneous_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae29ce-daa8-4b01-a965-6a810ecba9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_strict_ - correct_nulls_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76efda4d-ef31-40ee-963f-d430e692e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_strict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66ff25e-65d2-46fe-96eb-4d5d79a0aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_nulls_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0243d9-f577-4c49-95c1-67c2c8fce4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc81a0-8e23-41f9-8dfd-ff598943fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_strict/len(el_2_fr_vec_rslts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b327e1-fdd8-47db-80d8-e7b98df0d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(tp_strict+65)/len(el_2_fr_vec_rslts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a5a06-3fe3-403d-af10-029a4bcde66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_lax/len(el_2_fr_vec_rslts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c27b93-0f1b-4780-b2f1-4803c41a8506",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(errors)/len(el_2_fr_vec_rslts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da9332d-ec0e-4cad-aff8-050046b1b2a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb6e91-1c70-452a-9ea0-25382728c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grk_sent_2_section_name[6097]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc56b02-eb76-4f7a-8fa3-67c78a8e5926",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_sent_2_section_name[16839]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dea2f0-db7b-48ea-b3ed-ff6004709039",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a425fe-ab08-40ac-94e3-26d7fc0eaf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_strict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5976c931-f545-48ef-a37c-83f6f751c86a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# thuc_fr_chap_sents = []\n",
    "# for section in txt_no_markers:\n",
    "#     segmented_section = preprocess_series(section, \"fr\", True, None)\n",
    "#     thuc_fr_chap_sents.append(segmented_section) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813c20ef-f598-455f-be43-2665cf6bbf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_sents = 0\n",
    "# rslt_chaps = []\n",
    "# for chap in thuc_fr_chap_sents:\n",
    "#     rslt_sents = []\n",
    "#     for sent in chap:\n",
    "#         rslt_sents.extend(sent.split(\"\\n\"))\n",
    "#     num_sents += len(rslt_sents)\n",
    "#     rslt_chaps.append(rslt_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6f43c-af85-4be6-bab4-69211c3d3817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thuc_fr_chap_sents[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c789f3-26ce-4703-9f7f-fdeb3b7bb833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rslt_chaps[-1][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be647f90-214f-43ed-a244-9a1a7a2cdae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fullstring_split = load_txt_as_lst(\"/home/craig.car/spring2023/data/align_noisy_data/thuc_fr_1863_processed_2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d23a5a-1500-497a-bb55-2297826634df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chap_newline_sents = flatten_list(rslt_chaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d703e9b-bd46-456d-bbb7-70bbef6f86cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, row in enumerate(zip(fullstring_split, chap_newline_sents)):\n",
    "#     full_sent = row[0].strip()\n",
    "#     chap_newline_sent = row[1].strip()\n",
    "#     if full_sent != chap_newline_sent:\n",
    "#         print(i)\n",
    "#         print(\"full ================ sent\")\n",
    "#         print(full_sent)\n",
    "#         print(\"chapter ============= sent\")\n",
    "#         print(chap_newline_sent)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236f2c5-be8b-4358-ac7a-37312e56287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chap_newline_sents[2994]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47932e5c-c918-4476-ba58-f472ebc9b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1+109+87+105+116+134+116+103+145+8+8+1 = 933 (counting sections from end)\n",
    "# len(thuc_fr_chap_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de19d0-38c7-4eaf-a98a-500dad1aba74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# thuc_fr_chap_sents[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd678884-9fa5-4dcd-af38-6ffd5206a93d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get num sentences per section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6a765-5f1a-49ce-a6ff-e4ea840f676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # chap_num_2_length_chap = {}\n",
    "# idx_thuc_fr_chap_sents_2_section_length = {}\n",
    "# for idx, section in enumerate(thuc_fr_chap_sents):\n",
    "#     idx_thuc_fr_chap_sents_2_section_length[idx] = len(section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e7833e-29e9-4715-b158-6a8acd6d8b31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# idx_thuc_fr_chap_sents_2_section_length[932]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e8e8cf-7c32-46a6-97d3-c51c24f3f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(thuc_fr_chap_sents[932])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022de25-8455-407e-b6a0-94121a681480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(idx_thuc_fr_chap_sents_2_section_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc36fdf-4be4-4c9b-8889-456acd69cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# section_name_2_section_length = {}\n",
    "# for key, value in idx_thuc_fr_chap_sents_2_section_name.items():\n",
    "#     section_name_2_section_length[value] = idx_thuc_fr_chap_sents_2_section_length[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82141ec8-42c0-4db3-87f1-3780803eae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check values match across dicts\n",
    "# list(idx_thuc_fr_chap_sents_2_section_length.values()) == list(section_name_2_section_length.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f26115e-269e-4eec-942b-b127d009cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(section_name_2_section_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f90a04a-6897-4eed-bf24-6e8ac0cbd931",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TODO: doesn't match length of processed txt doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb26b26-dc7f-416e-85a6-d53d5d256927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lengths = list(idx_thuc_fr_chap_sents_2_section_length.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e77ac-e21a-4112-b451-9914a671dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521443e-da2b-4f61-8e3d-ffa1153fa7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # newline in sent 3 below isn't creating a line break, but it is in the processed text written to file\n",
    "# thuc_fr_chap_sents[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595e3fbb-5cf7-497c-b710-8b8531186fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_thuc_fr_chap_sents_2_section_length[59]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d3901-c58c-4690-aecc-e1cb75ceeb0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## build dict of sent_idx_2_section_name using section_name_2_section_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1ebfa6-e10f-4284-8f17-da8a126a2354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fr_sent_id_2_section_name = {}\n",
    "# last_num = -1\n",
    "# # e.g. key is \"1,1\" and value is 6 (num of sents in 1,1)\n",
    "# for key, value in section_name_2_section_length.items():\n",
    "#     for num in range(1, value+1):\n",
    "#         sent_idx = num+last_num\n",
    "#         fr_sent_id_2_section_name[sent_idx] = key\n",
    "#     last_num += value+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e600df-68c2-49ff-950d-8eacba55c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(fr_sent_id_2_section_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ea52f5-af42-46fe-bad0-9c4aa58beb11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fr_sent_id_2_section_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef10e6-48e9-482c-a45f-124456b9800e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e61478-bd5d-493e-b972-0c09765081d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
